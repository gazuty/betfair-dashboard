{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "1tbV1No038w0xJfNjEoodAMRm4uZdXZEj",
      "authorship_tag": "ABX9TyMnBknwMD6PREkPMbVIeykE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gazuty/betfair-dashboard/blob/main/Results.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- CONFIGURATION ---\n",
        "\n",
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "# ‚îÄ‚îÄ‚îÄ Your Drive / folder paths ‚îÄ‚îÄ‚îÄ\n",
        "BASE_FOLDER       = '/content/drive/My Drive/Betfair'\n",
        "MASTER_CSV        = os.path.join(BASE_FOLDER, 'Betfair_Master.csv')\n",
        "ARCHIVE_FOLDER    = os.path.join(BASE_FOLDER, 'Archive')\n",
        "BETTING_PATTERN   = os.path.join(BASE_FOLDER, 'BettingPandL*.csv')\n",
        "\n",
        "# ‚îÄ‚îÄ‚îÄ Google Sheet settings ‚îÄ‚îÄ‚îÄ\n",
        "GOOGLE_SHEET_NAME = 'Betfair Dashboard'\n",
        "\n",
        "# ‚îÄ‚îÄ‚îÄ Business rules ‚îÄ‚îÄ‚îÄ\n",
        "VALID_SPORTS      = ['Horse Racing', 'Greyhound Racing']\n",
        "MIN_STRIKE_BETS   = 50\n",
        "\n",
        "# ‚îÄ‚îÄ‚îÄ Setup ‚îÄ‚îÄ‚îÄ\n",
        "os.makedirs(ARCHIVE_FOLDER, exist_ok=True)\n",
        "\n",
        "print(\"‚úÖ Configuration loaded:\")\n",
        "print(f\"  BASE_FOLDER        = {BASE_FOLDER}\")\n",
        "print(f\"  MASTER_CSV         = {MASTER_CSV}\")\n",
        "print(f\"  ARCHIVE_FOLDER     = {ARCHIVE_FOLDER}\")\n",
        "print(f\"  BETTING_PATTERN    = {BETTING_PATTERN}\")\n",
        "print(f\"  GOOGLE_SHEET_NAME  = {GOOGLE_SHEET_NAME}\")\n",
        "print(f\"  VALID_SPORTS       = {VALID_SPORTS}\")\n",
        "print(f\"  MIN_STRIKE_BETS    = {MIN_STRIKE_BETS}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fy268ho4Fip2",
        "outputId": "9a358fdd-fe05-46a4-9dcc-417f8e492778"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Configuration loaded:\n",
            "  BASE_FOLDER        = /content/drive/My Drive/Betfair\n",
            "  MASTER_CSV         = /content/drive/My Drive/Betfair/Betfair_Master.csv\n",
            "  ARCHIVE_FOLDER     = /content/drive/My Drive/Betfair/Archive\n",
            "  BETTING_PATTERN    = /content/drive/My Drive/Betfair/BettingPandL*.csv\n",
            "  GOOGLE_SHEET_NAME  = Betfair Dashboard\n",
            "  VALID_SPORTS       = ['Horse Racing', 'Greyhound Racing']\n",
            "  MIN_STRIKE_BETS    = 50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- STEP 1: Master Updater ---\n",
        "\n",
        "import pandas as pd, glob, os, shutil\n",
        "\n",
        "REQUIRED_COLS = ['Market', 'Settled date']\n",
        "\n",
        "def update_betfair_master():\n",
        "    print(\"üîÑ Starting master update\")\n",
        "\n",
        "    # 1Ô∏è‚É£ Load or initialize master\n",
        "    if os.path.exists(MASTER_CSV):\n",
        "        df_master = pd.read_csv(MASTER_CSV)\n",
        "        df_master['Settled date'] = pd.to_datetime(df_master['Settled date'], errors='coerce')\n",
        "        df_master['Profit_Loss'] = pd.to_numeric(df_master['Profit_Loss'], errors='coerce')\n",
        "        df_master = df_master.dropna(subset=['Settled date']).reset_index(drop=True)\n",
        "        print(f\"‚úÖ Loaded master ({len(df_master)} rows)\")\n",
        "    else:\n",
        "        print(\"‚ö† No existing master found ‚Äî starting fresh\")\n",
        "        df_master = pd.DataFrame(columns=REQUIRED_COLS + ['Profit_Loss'])\n",
        "\n",
        "    # 2Ô∏è‚É£ Gather raw files\n",
        "    raw_files = glob.glob(BETTING_PATTERN)\n",
        "    print(f\"üìÇ Found {len(raw_files)} raw file(s)\")\n",
        "\n",
        "    if not raw_files:\n",
        "        print(\"‚ö† No raw files to process ‚Äî exiting.\")\n",
        "        return\n",
        "\n",
        "    # 3Ô∏è‚É£ Process each file\n",
        "    dfs = []\n",
        "    for filepath in raw_files:\n",
        "        fname = os.path.basename(filepath)\n",
        "        print(f\"üì• {fname}\", end=\"\")\n",
        "\n",
        "        df = pd.read_csv(filepath)\n",
        "        missing = [c for c in REQUIRED_COLS if c not in df.columns]\n",
        "        if missing:\n",
        "            print(f\" ‚Üí ‚ùå missing columns {missing}\")\n",
        "            continue\n",
        "\n",
        "        profs = [c for c in df.columns if 'profit' in c.lower()]\n",
        "        if not profs:\n",
        "            print(\" ‚Üí ‚ùå no profit column found\")\n",
        "            continue\n",
        "\n",
        "        pick = next((c for c in profs if 'aud' in c.lower()), profs[0])\n",
        "        df['Profit_Loss'] = pd.to_numeric(df[pick], errors='coerce')\n",
        "        df['Settled date'] = pd.to_datetime(df['Settled date'], errors='coerce')\n",
        "        df = df[['Market', 'Settled date', 'Profit_Loss']].dropna(subset=['Settled date'])\n",
        "\n",
        "        dfs.append(df)\n",
        "        print(f\" ‚Üí {len(df)} rows from '{pick}'\")\n",
        "\n",
        "    if not dfs:\n",
        "        print(\"‚ö† No valid data loaded from raw files ‚Äî exiting.\")\n",
        "        return\n",
        "\n",
        "    # 4Ô∏è‚É£ Combine and deduplicate\n",
        "    df_new = pd.concat(dfs, ignore_index=True)\n",
        "\n",
        "    # Drop invalid dates (again, to be safe)\n",
        "    df_new = df_new.dropna(subset=['Settled date']).reset_index(drop=True)\n",
        "\n",
        "    # Prepare deduplication keys\n",
        "    df_master['_key'] = (\n",
        "        df_master['Market'].astype(str) + \"|\" +\n",
        "        df_master['Settled date'].dt.strftime('%Y-%m-%d %H:%M:%S') + \"|\" +\n",
        "        df_master['Profit_Loss'].astype(str)\n",
        "    )\n",
        "    df_new['_key'] = (\n",
        "        df_new['Market'].astype(str) + \"|\" +\n",
        "        df_new['Settled date'].dt.strftime('%Y-%m-%d %H:%M:%S') + \"|\" +\n",
        "        df_new['Profit_Loss'].astype(str)\n",
        "    )\n",
        "\n",
        "    df_unique = df_new[~df_new['_key'].isin(df_master['_key'])]\n",
        "    print(f\"‚úÖ {len(df_unique)} unique new row(s) identified\")\n",
        "\n",
        "    # 5Ô∏è‚É£ Merge and save\n",
        "    if not df_unique.empty:\n",
        "        df_combined = pd.concat([\n",
        "            df_master.drop(columns=['_key']),\n",
        "            df_unique.drop(columns=['_key'])\n",
        "        ], ignore_index=True)\n",
        "        df_combined.to_csv(MASTER_CSV, index=False)\n",
        "        print(f\"‚úÖ Master updated ({len(df_combined)} rows) ‚Üí {MASTER_CSV}\")\n",
        "    else:\n",
        "        print(\"‚ö† No new rows to add ‚Äî master unchanged.\")\n",
        "\n",
        "    # 6Ô∏è‚É£ Archive files\n",
        "    for filepath in raw_files:\n",
        "        fname = os.path.basename(filepath)\n",
        "        shutil.move(filepath, os.path.join(ARCHIVE_FOLDER, fname))\n",
        "        print(f\"üì¶ Archived {fname}\")\n",
        "\n",
        "# Run the function\n",
        "update_betfair_master()\n"
      ],
      "metadata": {
        "id": "6Bgp_pFfIjKv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d9b1bcf-be7b-4204-d11d-0a86181a033c"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîÑ Starting master update\n",
            "‚úÖ Loaded master (18911 rows)\n",
            "üìÇ Found 0 raw file(s)\n",
            "‚ö† No raw files to process ‚Äî exiting.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- STEP 2: Load Master ---\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "print(f\"üìÇ Loading master from: {MASTER_CSV}\")\n",
        "df = pd.read_csv(MASTER_CSV)\n",
        "\n",
        "# Ensure correct dtypes\n",
        "df['Settled date'] = pd.to_datetime(df['Settled date'], errors='coerce')\n",
        "df['Profit_Loss'] = pd.to_numeric(df['Profit_Loss'], errors='coerce')\n",
        "\n",
        "# Drop rows with invalid dates\n",
        "before = len(df)\n",
        "df = df.dropna(subset=['Settled date']).reset_index(drop=True)\n",
        "after = len(df)\n",
        "\n",
        "print(f\"‚úÖ {after} rows loaded (dropped {before - after} invalid dates).\")\n",
        "print(f\"   Profit_Loss dtype: {df['Profit_Loss'].dtype}\")\n"
      ],
      "metadata": {
        "id": "Ag8x2FTv98Bd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d38e378a-916c-4e73-8971-b48eae7cd87b"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÇ Loading master from: /content/drive/My Drive/Betfair/Betfair_Master.csv\n",
            "‚úÖ 18911 rows loaded (dropped 0 invalid dates).\n",
            "   Profit_Loss dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- STEP 3: Feature Extraction ---\n",
        "\n",
        "# 1Ô∏è‚É£ Extract Sport from Market (first token before slash)\n",
        "df['Sport'] = df['Market'].str.extract(r'^([^/]+)/')[0].str.strip()\n",
        "\n",
        "# 2Ô∏è‚É£ Extract Track_Info and Event_Description for racing sports\n",
        "racing_mask = df['Sport'].isin(VALID_SPORTS)\n",
        "track_event = df.loc[racing_mask, 'Market'].str.extract(r'/\\s*(.*?)\\s*:\\s*(.*)')\n",
        "track_event.columns = ['Track_Info', 'Event_Description']\n",
        "df.loc[racing_mask, ['Track_Info', 'Event_Description']] = track_event\n",
        "\n",
        "# 3Ô∏è‚É£ Extract Country from parentheses in Track_Info\n",
        "df['Country'] = df['Track_Info'].str.extract(r'\\(([^)]+)\\)')[0]\n",
        "\n",
        "# 4Ô∏è‚É£ Fill missing country values\n",
        "df['Country'] = df['Country'].fillna('UK')  # Default to UK for missing codes\n",
        "df.loc[~df['Sport'].isin(VALID_SPORTS), 'Country'] = 'Unknown'  # Unknown for non-racing\n",
        "\n",
        "# 5Ô∏è‚É£ Clean up Track_Info to produce Track_Name (remove dates and country)\n",
        "df['Track_Name'] = (\n",
        "    df['Track_Info']\n",
        "      .str.replace(r'\\([^)]*\\)', '', regex=True)  # Remove (AUS), (US), etc.\n",
        "      .str.replace(r'\\b\\d{1,2}(?:st|nd|rd|th)?\\s+\\w+\\b', '', regex=True)  # Remove date-like tokens\n",
        "      .str.strip()\n",
        ")\n",
        "\n",
        "# 6Ô∏è‚É£ Preview output\n",
        "preview = df.loc[df['Track_Name'].notna(), ['Sport', 'Track_Name', 'Country']].drop_duplicates().head(10)\n",
        "print(\"‚úÖ Feature extraction complete ‚Äî first few tracks:\")\n",
        "print(preview)\n"
      ],
      "metadata": {
        "id": "3h7weeM--HWz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "823309e7-4f29-4755-a253-fc34f8a94cb1"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Feature extraction complete ‚Äî first few tracks:\n",
            "           Sport            Track_Name Country\n",
            "2   Horse Racing              Ballarat     AUS\n",
            "3   Horse Racing             Casterton     AUS\n",
            "5   Horse Racing          Charles Town      US\n",
            "6   Horse Racing       Canterbury Park      US\n",
            "7   Horse Racing      Evangeline Downs      US\n",
            "8   Horse Racing       Churchill Downs      US\n",
            "10  Horse Racing  Belmont At The Big A      US\n",
            "11  Horse Racing              Woodbine      US\n",
            "13  Horse Racing         Monmouth Park      US\n",
            "14  Horse Racing             Doncaster      UK\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- STEP 4: Build summary tables (daily, weekly, monthly, sport, country) ---\n",
        "\n",
        "# 1Ô∏è‚É£ By Day (chronological daily summary with cumulative P/L)\n",
        "by_day = (\n",
        "    df.groupby(df['Settled date'].dt.date)['Profit_Loss']\n",
        "      .sum()\n",
        "      .reset_index(name='Profit_Loss')\n",
        "      .rename(columns={'Settled date': 'Day'})\n",
        ")\n",
        "by_day = by_day.sort_values('Day').reset_index(drop=True)\n",
        "by_day['Cumulative_Profit_Loss'] = by_day['Profit_Loss'].cumsum()\n",
        "by_day[['Profit_Loss', 'Cumulative_Profit_Loss']] = by_day[['Profit_Loss', 'Cumulative_Profit_Loss']].round(2)\n",
        "\n",
        "# 2Ô∏è‚É£ By Week (starts Mondays)\n",
        "by_week = (\n",
        "    df.set_index('Settled date')\n",
        "      .resample('W-MON')['Profit_Loss']\n",
        "      .sum()\n",
        "      .reset_index()\n",
        "      .rename(columns={'Settled date': 'Week Starting'})\n",
        ")\n",
        "by_week['Profit_Loss'] = by_week['Profit_Loss'].round(2)\n",
        "\n",
        "# 3Ô∏è‚É£ By Month\n",
        "by_month = (\n",
        "    df.set_index('Settled date')\n",
        "      .resample('M')['Profit_Loss']\n",
        "      .sum()\n",
        "      .reset_index()\n",
        ")\n",
        "by_month['Month'] = by_month['Settled date'].dt.to_period('M').astype(str)\n",
        "by_month = by_month[['Month', 'Profit_Loss']]\n",
        "by_month['Profit_Loss'] = by_month['Profit_Loss'].round(2)\n",
        "\n",
        "# 4Ô∏è‚É£ By Sport\n",
        "by_sport = (\n",
        "    df.groupby('Sport')['Profit_Loss']\n",
        "      .sum()\n",
        "      .reset_index()\n",
        "      .round({'Profit_Loss': 2})\n",
        ")\n",
        "\n",
        "# 5Ô∏è‚É£ By Country\n",
        "by_country = (\n",
        "    df.groupby('Country')['Profit_Loss']\n",
        "      .sum()\n",
        "      .reset_index()\n",
        "      .round({'Profit_Loss': 2})\n",
        ")\n",
        "\n",
        "# 6Ô∏è‚É£ Daily summaries for each sport (with cumulative P/L)\n",
        "sport_daily = {}\n",
        "for sport in df['Sport'].dropna().unique():\n",
        "    temp = (\n",
        "        df[df['Sport'] == sport]\n",
        "          .groupby(df['Settled date'].dt.date)['Profit_Loss']\n",
        "          .sum()\n",
        "          .reset_index(name='Profit_Loss')\n",
        "          .rename(columns={'Settled date': 'Day'})\n",
        "          .sort_values('Day')\n",
        "          .reset_index(drop=True)\n",
        "    )\n",
        "    temp['Cumulative_Profit_Loss'] = temp['Profit_Loss'].cumsum().round(2)\n",
        "    temp['Profit_Loss'] = temp['Profit_Loss'].round(2)\n",
        "    sport_daily[f\"{sport} Daily\"] = temp\n",
        "\n",
        "# 7Ô∏è‚É£ Final summary checks\n",
        "print(f\"‚úÖ By Day: {len(by_day)} rows (last: {by_day['Day'].max()})\")\n",
        "print(f\"‚úÖ By Week: {len(by_week)} rows (last: {by_week['Week Starting'].max().date()})\")\n",
        "print(f\"‚úÖ By Month: {len(by_month)} rows (last: {by_month['Month'].max()})\")\n",
        "print(f\"‚úÖ By Sport: {len(by_sport)} sports ‚Üí {by_sport['Sport'].tolist()}\")\n",
        "print(f\"‚úÖ By Country: {len(by_country)} countries ‚Üí {by_country['Country'].tolist()}\")\n"
      ],
      "metadata": {
        "id": "V_K4tw9-cWvw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4a146be-7692-4139-dbaf-4415d7bd2946"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ By Day: 193 rows (last: 2025-07-12)\n",
            "‚úÖ By Week: 28 rows (last: 2025-07-14)\n",
            "‚úÖ By Month: 7 rows (last: 2025-07)\n",
            "‚úÖ By Sport: 14 sports ‚Üí ['American Football', 'Basketball', 'Cricket', 'Darts', 'Football', 'Golf', 'Greyhound Racing', 'Horse Racing', 'Ice Hockey', 'Motor Sport', 'Politics', 'Rugby Union', 'Snooker', 'Tennis']\n",
            "‚úÖ By Country: 8 countries ‚Üí ['AUS', 'FRA', 'NZL', 'RSA', 'UAE', 'UK', 'US', 'Unknown']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-44-119278825.py:27: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
            "  .resample('M')['Profit_Loss']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- STEP 5: Track Summaries ---\n",
        "\n",
        "# 1Ô∏è‚É£ Aggregate P/L per track for Horse and Greyhound Racing\n",
        "track_df = (\n",
        "    df[df['Sport'].isin(VALID_SPORTS)]\n",
        "      .groupby(['Sport', 'Track_Name'], as_index=False)['Profit_Loss']\n",
        "      .sum()\n",
        ")\n",
        "track_df['Profit_Loss'] = track_df['Profit_Loss'].round(2)\n",
        "\n",
        "# 2Ô∏è‚É£ Create summary groups\n",
        "tracks = {\n",
        "    'Track Stats':               track_df,\n",
        "    'Top Horse Tracks':          track_df.query(\"Sport == 'Horse Racing'\").nlargest(15, 'Profit_Loss'),\n",
        "    'Bottom Horse Tracks':       track_df.query(\"Sport == 'Horse Racing'\").nsmallest(15, 'Profit_Loss'),\n",
        "    'Top Greyhound Tracks':      track_df.query(\"Sport == 'Greyhound Racing'\").nlargest(15, 'Profit_Loss'),\n",
        "    'Bottom Greyhound Tracks':   track_df.query(\"Sport == 'Greyhound Racing'\").nsmallest(15, 'Profit_Loss'),\n",
        "}\n",
        "\n",
        "# 3Ô∏è‚É£ Preview sample\n",
        "print(\"‚úÖ Track summaries built.\")\n",
        "print(\" ‚Ä¢ Sample Track Stats:\")\n",
        "print(track_df.head())\n",
        "print(\" ‚Ä¢ Top Horse Tracks:\")\n",
        "print(tracks['Top Horse Tracks'][['Track_Name', 'Profit_Loss']].head())\n"
      ],
      "metadata": {
        "id": "nFAP0CNsccL9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9dd52a2b-e2df-468c-d66c-4362421964b1"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Track summaries built.\n",
            " ‚Ä¢ Sample Track Stats:\n",
            "              Sport   Track_Name  Profit_Loss\n",
            "0  Greyhound Racing  Albion Park        91.77\n",
            "1  Greyhound Racing   Angle Park      -128.51\n",
            "2  Greyhound Racing     Ballarat        84.36\n",
            "3  Greyhound Racing      Bendigo        24.32\n",
            "4  Greyhound Racing  Broken Hill        52.63\n",
            " ‚Ä¢ Top Horse Tracks:\n",
            "    Track_Name  Profit_Loss\n",
            "169  Geraldton      1400.78\n",
            "57     Aintree      1286.07\n",
            "297   Rosehill      1198.06\n",
            "255  Newcastle      1030.43\n",
            "315  Southwell      1026.10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- STEP 6: Strike Rates ---\n",
        "\n",
        "# 1Ô∏è‚É£ Filter to Horse & Greyhound Racing\n",
        "df_racing = df[df['Sport'].isin(VALID_SPORTS)].copy()\n",
        "\n",
        "# 2Ô∏è‚É£ Compute total bets and wins per track\n",
        "strike_df = (\n",
        "    df_racing\n",
        "      .groupby(['Sport', 'Track_Name'])['Profit_Loss']\n",
        "      .agg(\n",
        "          total_bets='count',\n",
        "          wins=lambda x: (x > 0).sum()\n",
        "      )\n",
        "      .reset_index()\n",
        ")\n",
        "\n",
        "# 3Ô∏è‚É£ Calculate strike rate\n",
        "strike_df['Strike_Rate'] = (strike_df['wins'] / strike_df['total_bets']).round(4)\n",
        "\n",
        "# 4Ô∏è‚É£ Filter by minimum bets threshold\n",
        "strike_df_filtered = strike_df[strike_df['total_bets'] >= MIN_STRIKE_BETS].reset_index(drop=True)\n",
        "\n",
        "# 5Ô∏è‚É£ Extract Top & Bottom Strike Rate Tracks\n",
        "top_strike    = strike_df_filtered.nlargest(10, 'Strike_Rate').reset_index(drop=True)\n",
        "bottom_strike = strike_df_filtered.nsmallest(10, 'Strike_Rate').reset_index(drop=True)\n",
        "\n",
        "# 6Ô∏è‚É£ Preview\n",
        "print(f\"‚úÖ Strike rates computed (min {MIN_STRIKE_BETS} bets):\")\n",
        "print(\"Top 10 Strike Rates:\")\n",
        "print(top_strike[['Sport', 'Track_Name', 'total_bets', 'wins', 'Strike_Rate']])\n",
        "print(\"\\nBottom 10 Strike Rates:\")\n",
        "print(bottom_strike[['Sport', 'Track_Name', 'total_bets', 'wins', 'Strike_Rate']])\n"
      ],
      "metadata": {
        "id": "YrBPZlTccebQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83cb3f36-1ad5-4772-def8-711470ee9e47"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Strike rates computed (min 50 bets):\n",
            "Top 10 Strike Rates:\n",
            "          Sport              Track_Name  total_bets  wins  Strike_Rate\n",
            "0  Horse Racing                Rosehill          76    61       0.8026\n",
            "1  Horse Racing                    York          56    43       0.7679\n",
            "2  Horse Racing                 Chester          51    39       0.7647\n",
            "3  Horse Racing                 Newbury          72    53       0.7361\n",
            "4  Horse Racing               Ellerslie          55    40       0.7273\n",
            "5  Horse Racing                Brighton          62    45       0.7258\n",
            "6  Horse Racing               Chantilly          72    52       0.7222\n",
            "7  Horse Racing             Musselburgh          59    42       0.7119\n",
            "8  Horse Racing  Horseshoe Indianapolis          94    66       0.7021\n",
            "9  Horse Racing                 Windsor          81    56       0.6914\n",
            "\n",
            "Bottom 10 Strike Rates:\n",
            "              Sport    Track_Name  total_bets  wins  Strike_Rate\n",
            "0  Greyhound Racing        Hobart         139    64       0.4604\n",
            "1  Greyhound Racing       Bendigo         156    73       0.4679\n",
            "2      Horse Racing  Charles Town          51    24       0.4706\n",
            "3  Greyhound Racing    Shepparton         140    66       0.4714\n",
            "4  Greyhound Racing  Q2 Parklands          89    42       0.4719\n",
            "5      Horse Racing    Kenilworth          83    40       0.4819\n",
            "6      Horse Racing     Greyville          56    27       0.4821\n",
            "7  Greyhound Racing    Launceston         165    80       0.4848\n",
            "8  Greyhound Racing   Q1 Lakeside         228   113       0.4956\n",
            "9      Horse Racing   Turffontein          77    39       0.5065\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- STEP 7: Prepare all_sheets for export ---\n",
        "\n",
        "# Core summaries\n",
        "all_sheets = {\n",
        "    'By Day':           by_day,\n",
        "    'By Day Sorted':    by_day.sort_values('Profit_Loss', ascending=False).reset_index(drop=True),\n",
        "    'By Week':          by_week,\n",
        "    'Cumulative':       by_day[['Day', 'Cumulative_Profit_Loss']].rename(columns={'Cumulative_Profit_Loss': 'Cumulative'}),\n",
        "    'By Month':         by_month,\n",
        "    'By Sport':         by_sport,\n",
        "    'By Country':       by_country,\n",
        "\n",
        "    # Track summaries\n",
        "    'Track Stats':             tracks['Track Stats'],\n",
        "    'Top Horse Tracks':        tracks['Top Horse Tracks'],\n",
        "    'Bottom Horse Tracks':     tracks['Bottom Horse Tracks'],\n",
        "    'Top Greyhound Tracks':    tracks['Top Greyhound Tracks'],\n",
        "    'Bottom Greyhound Tracks': tracks['Bottom Greyhound Tracks'],\n",
        "\n",
        "    # Strike rates\n",
        "    'Top Strike Rates':    top_strike,\n",
        "    'Bottom Strike Rates': bottom_strike,\n",
        "}\n",
        "\n",
        "# Add sport-specific daily performance tables\n",
        "all_sheets.update(sport_daily)\n",
        "\n",
        "# Summary\n",
        "print(f\"‚úÖ Prepared {len(all_sheets)} tables for export:\")\n",
        "for name in all_sheets:\n",
        "    print(f\"  ‚Ä¢ {name}\")\n"
      ],
      "metadata": {
        "id": "OP-sN4D9cgqN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5685bf03-6986-42e3-ef2c-ac195bdbc443"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Prepared 28 tables for export:\n",
            "  ‚Ä¢ By Day\n",
            "  ‚Ä¢ By Day Sorted\n",
            "  ‚Ä¢ By Week\n",
            "  ‚Ä¢ Cumulative\n",
            "  ‚Ä¢ By Month\n",
            "  ‚Ä¢ By Sport\n",
            "  ‚Ä¢ By Country\n",
            "  ‚Ä¢ Track Stats\n",
            "  ‚Ä¢ Top Horse Tracks\n",
            "  ‚Ä¢ Bottom Horse Tracks\n",
            "  ‚Ä¢ Top Greyhound Tracks\n",
            "  ‚Ä¢ Bottom Greyhound Tracks\n",
            "  ‚Ä¢ Top Strike Rates\n",
            "  ‚Ä¢ Bottom Strike Rates\n",
            "  ‚Ä¢ Snooker Daily\n",
            "  ‚Ä¢ Ice Hockey Daily\n",
            "  ‚Ä¢ Horse Racing Daily\n",
            "  ‚Ä¢ Golf Daily\n",
            "  ‚Ä¢ Politics Daily\n",
            "  ‚Ä¢ Tennis Daily\n",
            "  ‚Ä¢ Greyhound Racing Daily\n",
            "  ‚Ä¢ Football Daily\n",
            "  ‚Ä¢ Motor Sport Daily\n",
            "  ‚Ä¢ Cricket Daily\n",
            "  ‚Ä¢ Darts Daily\n",
            "  ‚Ä¢ Basketball Daily\n",
            "  ‚Ä¢ American Football Daily\n",
            "  ‚Ä¢ Rugby Union Daily\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"üìä Top Horse Tracks preview:\")\n",
        "print(tracks['Top Horse Tracks'].head())\n",
        "print(\"üìä Bottom Horse Tracks preview:\")\n",
        "print(tracks['Bottom Horse Tracks'].head())\n"
      ],
      "metadata": {
        "id": "NfU0nlBeNY4n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f8099b6-300c-4b81-e91a-09d8b04871b2"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìä Top Horse Tracks preview:\n",
            "            Sport Track_Name  Profit_Loss\n",
            "169  Horse Racing  Geraldton      1400.78\n",
            "57   Horse Racing    Aintree      1286.07\n",
            "297  Horse Racing   Rosehill      1198.06\n",
            "255  Horse Racing  Newcastle      1030.43\n",
            "315  Horse Racing  Southwell      1026.10\n",
            "üìä Bottom Horse Tracks preview:\n",
            "            Sport    Track_Name  Profit_Loss\n",
            "344  Horse Racing  Turfway Park      -336.93\n",
            "292  Horse Racing         Ripon      -154.66\n",
            "360  Horse Racing     Wincanton      -129.13\n",
            "358  Horse Racing      Wetherby      -103.88\n",
            "113  Horse Racing  Charles Town       -89.48\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- STEP 8: Export to Google Sheets ---\n",
        "\n",
        "import gspread\n",
        "from gspread_dataframe import set_with_dataframe\n",
        "from google.colab import auth\n",
        "from google.auth import default\n",
        "from datetime import date\n",
        "\n",
        "# 1Ô∏è‚É£ Authenticate and connect\n",
        "auth.authenticate_user()\n",
        "creds, _ = default()\n",
        "gc = gspread.authorize(creds)\n",
        "\n",
        "# 2Ô∏è‚É£ Open Google Sheet\n",
        "sh = next((s for s in gc.openall() if s.title == GOOGLE_SHEET_NAME), None)\n",
        "if not sh:\n",
        "    raise Exception(f\"‚ùå Sheet not found: {GOOGLE_SHEET_NAME}\")\n",
        "print(f\"‚úÖ Connected to '{GOOGLE_SHEET_NAME}'\")\n",
        "\n",
        "# 3Ô∏è‚É£ Upload each table\n",
        "for name, df_out in all_sheets.items():\n",
        "    # Format Profit_Loss\n",
        "    if 'Profit_Loss' in df_out.columns:\n",
        "        df_out['Profit_Loss'] = pd.to_numeric(df_out['Profit_Loss'], errors='coerce').round(2)\n",
        "        df_out['Profit_Loss'] = df_out['Profit_Loss'].map(lambda x: f\"{x:.2f}\" if pd.notnull(x) else \"\")\n",
        "\n",
        "    # Format week date\n",
        "    if 'Week Starting' in df_out.columns:\n",
        "        df_out['Week Starting'] = df_out['Week Starting'].astype(str)\n",
        "\n",
        "    # Round other numeric columns\n",
        "    for col in df_out.select_dtypes(include=['float', 'int']).columns:\n",
        "        df_out[col] = df_out[col].round(2)\n",
        "\n",
        "    # Upload to sheet\n",
        "    try:\n",
        "        ws = sh.worksheet(name)\n",
        "        ws.clear()\n",
        "    except gspread.exceptions.WorksheetNotFound:\n",
        "        ws = sh.add_worksheet(title=name, rows=1000, cols=20)\n",
        "\n",
        "    set_with_dataframe(ws, df_out)\n",
        "    print(f\"‚úÖ Uploaded tab: {name}\")\n",
        "\n",
        "# 4Ô∏è‚É£ Update KPI dashboard\n",
        "try:\n",
        "    dash = sh.worksheet('Dashboard')\n",
        "    dash.clear()\n",
        "except gspread.exceptions.WorksheetNotFound:\n",
        "    dash = sh.add_worksheet('Dashboard', rows=10, cols=5)\n",
        "\n",
        "total_profit = round(df['Profit_Loss'].sum(), 2)\n",
        "total_bets   = len(df)\n",
        "best_day     = df.groupby(df['Settled date'].dt.date)['Profit_Loss'].sum().idxmax()\n",
        "worst_day    = df.groupby(df['Settled date'].dt.date)['Profit_Loss'].sum().idxmin()\n",
        "\n",
        "kpis = [\n",
        "    ['Metric', 'Value'],\n",
        "    ['Total Profit/Loss', total_profit],\n",
        "    ['Number of Bets', total_bets],\n",
        "    ['Best Day', str(best_day)],\n",
        "    ['Worst Day', str(worst_day)],\n",
        "    ['Generated on', str(date.today())]\n",
        "]\n",
        "dash.update(values=kpis, range_name='A1')\n",
        "\n",
        "print(\"‚úÖ Dashboard KPIs updated\")\n"
      ],
      "metadata": {
        "id": "sw42u_CuCOsx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4fc9e293-bfd2-4124-879f-210a76a0b29d"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Connected to 'Betfair Dashboard'\n",
            "‚úÖ Uploaded tab: By Day\n",
            "‚úÖ Uploaded tab: By Day Sorted\n",
            "‚úÖ Uploaded tab: By Week\n",
            "‚úÖ Uploaded tab: Cumulative\n",
            "‚úÖ Uploaded tab: By Month\n",
            "‚úÖ Uploaded tab: By Sport\n",
            "‚úÖ Uploaded tab: By Country\n",
            "‚úÖ Uploaded tab: Track Stats\n",
            "‚úÖ Uploaded tab: Top Horse Tracks\n",
            "‚úÖ Uploaded tab: Bottom Horse Tracks\n",
            "‚úÖ Uploaded tab: Top Greyhound Tracks\n",
            "‚úÖ Uploaded tab: Bottom Greyhound Tracks\n",
            "‚úÖ Uploaded tab: Top Strike Rates\n",
            "‚úÖ Uploaded tab: Bottom Strike Rates\n",
            "‚úÖ Uploaded tab: Snooker Daily\n",
            "‚úÖ Uploaded tab: Ice Hockey Daily\n",
            "‚úÖ Uploaded tab: Horse Racing Daily\n",
            "‚úÖ Uploaded tab: Golf Daily\n",
            "‚úÖ Uploaded tab: Politics Daily\n",
            "‚úÖ Uploaded tab: Tennis Daily\n",
            "‚úÖ Uploaded tab: Greyhound Racing Daily\n",
            "‚úÖ Uploaded tab: Football Daily\n",
            "‚úÖ Uploaded tab: Motor Sport Daily\n",
            "‚úÖ Uploaded tab: Cricket Daily\n",
            "‚úÖ Uploaded tab: Darts Daily\n",
            "‚úÖ Uploaded tab: Basketball Daily\n",
            "‚úÖ Uploaded tab: American Football Daily\n",
            "‚úÖ Uploaded tab: Rugby Union Daily\n",
            "‚úÖ Dashboard KPIs updated\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_sII6iunFgwZ"
      },
      "execution_count": 49,
      "outputs": []
    }
  ]
}