{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "1tbV1No038w0xJfNjEoodAMRm4uZdXZEj",
      "authorship_tag": "ABX9TyOO39xOznZpdHul0hPoBhik",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gazuty/betfair-dashboard/blob/main/Results.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- STEP 1: Master Updater ---\n",
        "\n",
        "import os\n",
        "import glob\n",
        "import pandas as pd\n",
        "import shutil\n",
        "import hashlib\n",
        "\n",
        "def update_betfair_master():\n",
        "    BASE_FOLDER = '/content/drive/My Drive/Betfair'\n",
        "    ARCHIVE_FOLDER = os.path.join(BASE_FOLDER, 'Archive')\n",
        "    os.makedirs(ARCHIVE_FOLDER, exist_ok=True)\n",
        "\n",
        "    MASTER_CSV = os.path.join(BASE_FOLDER, 'Betfair_Master.csv')\n",
        "    BETTING_PATTERN = os.path.join(BASE_FOLDER, 'BettingPandL*.csv')\n",
        "    RESULTS_FILE = os.path.join(BASE_FOLDER, 'Results Summary export 25-05-11 095900.csv')\n",
        "\n",
        "    if os.path.exists(MASTER_CSV):\n",
        "        df_master = pd.read_csv(MASTER_CSV)\n",
        "        df_master['Settled date'] = pd.to_datetime(df_master['Settled date'], errors='coerce')\n",
        "        df_master['Profit_Loss'] = pd.to_numeric(df_master['Profit_Loss'], errors='coerce')\n",
        "        print(f\"âœ… Loaded master: {MASTER_CSV} ({len(df_master)} rows) Profit_Loss dtype: {df_master['Profit_Loss'].dtype}\")\n",
        "    else:\n",
        "        print(f\"âš  No master found â€” starting fresh.\")\n",
        "        df_master = pd.DataFrame()\n",
        "\n",
        "    # Find files\n",
        "    new_files = glob.glob(BETTING_PATTERN)\n",
        "    if os.path.exists(RESULTS_FILE):\n",
        "        new_files.append(RESULTS_FILE)\n",
        "\n",
        "    print(f\"ðŸ“‚ Found {len(new_files)} new file(s) to process.\")\n",
        "    if not new_files:\n",
        "        print(\"âš  No new data files found â€” master remains unchanged.\")\n",
        "        return\n",
        "\n",
        "    # Load and standardize\n",
        "    dfs_new = []\n",
        "    for file in new_files:\n",
        "        print(f\"ðŸ“¥ Processing: {os.path.basename(file)}\")\n",
        "        df = pd.read_csv(file)\n",
        "        if 'Profit / loss' in df.columns and 'Profit/Loss (AUD)' in df.columns:\n",
        "            df['Profit_Loss'] = df['Profit/Loss (AUD)'].fillna(df['Profit / loss'])\n",
        "        elif 'Profit/Loss (AUD)' in df.columns:\n",
        "            df['Profit_Loss'] = df['Profit_Loss (AUD)']\n",
        "        elif 'Profit / loss' in df.columns:\n",
        "            df['Profit_Loss'] = df['Profit / loss']\n",
        "        else:\n",
        "            print(f\"âš  Skipping {file} â€” no profit column found.\")\n",
        "            continue\n",
        "        df['Profit_Loss'] = pd.to_numeric(df['Profit_Loss'], errors='coerce')\n",
        "        dfs_new.append(df)\n",
        "\n",
        "    if not dfs_new:\n",
        "        print(\"âš  No valid new data loaded â€” master remains unchanged.\")\n",
        "        return\n",
        "\n",
        "    df_new = pd.concat(dfs_new, ignore_index=True)\n",
        "    df_new['Settled date'] = pd.to_datetime(df_new['Settled date'], errors='coerce')\n",
        "    df_new = df_new.dropna(subset=['Settled date']).reset_index(drop=True)\n",
        "\n",
        "    df_master['key'] = df_master['Market'].astype(str) + \"|\" + df_master['Settled date'].dt.strftime('%Y-%m-%d %H:%M:%S') + \"|\" + df_master['Profit_Loss'].astype(str)\n",
        "    df_new['key'] = df_new['Market'].astype(str) + \"|\" + df_new['Settled date'].dt.strftime('%Y-%m-%d %H:%M:%S') + \"|\" + df_new['Profit_Loss'].astype(str)\n",
        "\n",
        "    df_new_unique = df_new[~df_new['key'].isin(df_master['key'])]\n",
        "    print(f\"âœ… Identified {len(df_new_unique)} unique new row(s).\")\n",
        "\n",
        "    if not df_new_unique.empty:\n",
        "        df_combined = pd.concat([df_master.drop(columns=['key']), df_new_unique.drop(columns=['key'])], ignore_index=True)\n",
        "        df_combined['Profit_Loss'] = pd.to_numeric(df_combined['Profit_Loss'], errors='coerce')\n",
        "        print(f\"âœ… Final master row count: {len(df_combined)}. Profit_Loss dtype: {df_combined['Profit_Loss'].dtype}\")\n",
        "        df_combined.to_csv(MASTER_CSV, index=False)\n",
        "        print(f\"âœ… Master updated and saved to {MASTER_CSV}\")\n",
        "    else:\n",
        "        print(\"âš  No new rows added to master â€” no changes made.\")\n",
        "\n",
        "    # Archive files\n",
        "    for file in new_files:\n",
        "        shutil.move(file, os.path.join(ARCHIVE_FOLDER, os.path.basename(file)))\n",
        "        print(f\"ðŸ“¦ Archived {os.path.basename(file)}\")\n",
        "\n",
        "# Call the function to actually run it\n",
        "update_betfair_master()\n"
      ],
      "metadata": {
        "id": "6Bgp_pFfIjKv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b98bb5a3-24f5-4a97-faee-b7dd587becca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Loaded master: /content/drive/My Drive/Betfair/Betfair_Master.csv (18431 rows) Profit_Loss dtype: float64\n",
            "ðŸ“‚ Found 0 new file(s) to process.\n",
            "âš  No new data files found â€” master remains unchanged.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- STEP 2: Load Master ---\n",
        "\n",
        "df = pd.read_csv(MASTER_CSV)\n",
        "df['Settled date'] = pd.to_datetime(df['Settled date'], errors='coerce')\n",
        "df['Profit_Loss'] = pd.to_numeric(df['Profit_Loss'], errors='coerce')\n",
        "df = df.dropna(subset=['Settled date']).reset_index(drop=True)\n",
        "print(f\"âœ… Loaded {len(df)} rows for analysis. Profit_Loss dtype: {df['Profit_Loss'].dtype}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ag8x2FTv98Bd",
        "outputId": "8f344a5a-e71c-498c-9748-1a48cad23a22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Loaded 18431 rows for analysis. Profit_Loss dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- STEP 3: Extract Sport, clean Track_Name, and Country ---\n",
        "\n",
        "import re\n",
        "\n",
        "df['Sport'] = df['Market'].str.extract(r'^([^/]+)/')[0].str.strip()\n",
        "racing_df = df[df['Sport'].isin(['Horse Racing', 'Greyhound Racing'])].copy()\n",
        "racing_df[['Track_Info', 'Event_Description']] = racing_df['Market'].str.extract(r'/\\s*(.*?)\\s*:\\s*(.*)')\n",
        "\n",
        "def extract_track_and_country(track_info):\n",
        "    if pd.isna(track_info):\n",
        "        return pd.Series([None, 'Unknown'])\n",
        "    if '(' in track_info and ')' in track_info:\n",
        "        inside = track_info.split('(')[1].replace(')', '').strip()\n",
        "        country = inside.split()[0]\n",
        "        track = track_info.split('(')[0].strip()\n",
        "    else:\n",
        "        track = track_info.strip()\n",
        "        country = 'Unknown'\n",
        "    return pd.Series([track, country])\n",
        "\n",
        "def clean_track_name(track):\n",
        "    if pd.isna(track):\n",
        "        return None\n",
        "    return re.sub(r'\\b\\d{1,2}(st|nd|rd|th)?\\s\\w+\\b', '', track).strip()\n",
        "\n",
        "racing_df[['Track_Name_Raw', 'Country']] = racing_df['Track_Info'].apply(extract_track_and_country)\n",
        "racing_df['Track_Name'] = racing_df['Track_Name_Raw'].apply(clean_track_name)\n",
        "df = df.merge(racing_df[['Market', 'Track_Name', 'Country']], on='Market', how='left')\n",
        "print(f\"âœ… After feature extraction: {len(df)} rows, Profit_Loss dtype: {df['Profit_Loss'].dtype}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3h7weeM--HWz",
        "outputId": "c8095d80-b0d7-43ec-f57f-715396d603f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… After feature extraction: 20347 rows, Profit_Loss dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- STEP 4: Build complete summary tables (daily, cumulative, weekly, monthly, sport, country) ---\n",
        "\n",
        "df['Day'] = df['Settled date'].dt.date\n",
        "df['Month'] = df['Settled date'].dt.to_period('M').astype(str)\n",
        "df['Week Starting'] = (\n",
        "    df['Settled date'].dt.floor('D') -\n",
        "    pd.to_timedelta(df['Settled date'].dt.weekday, unit='d')\n",
        ")\n",
        "\n",
        "by_day = df.groupby('Day')['Profit_Loss'].sum().reset_index()\n",
        "by_day = by_day.sort_values('Day').reset_index(drop=True)\n",
        "by_day['Cumulative_Profit_Loss'] = by_day['Profit_Loss'].cumsum()\n",
        "by_day['Profit_Loss'] = pd.to_numeric(by_day['Profit_Loss'], errors='coerce').round(2)\n",
        "by_day['Cumulative_Profit_Loss'] = pd.to_numeric(by_day['Cumulative_Profit_Loss'], errors='coerce').round(2)\n",
        "\n",
        "by_week = df.groupby('Week Starting')['Profit_Loss'].sum().reset_index()\n",
        "by_week = by_week.sort_values('Week Starting').reset_index(drop=True)\n",
        "by_week['Profit_Loss'] = pd.to_numeric(by_week['Profit_Loss'], errors='coerce').round(2)\n",
        "\n",
        "by_month = df.groupby('Month')['Profit_Loss'].sum().reset_index()\n",
        "by_month['Profit_Loss'] = pd.to_numeric(by_month['Profit_Loss'], errors='coerce').round(2)\n",
        "\n",
        "by_sport = df.groupby('Sport')['Profit_Loss'].sum().reset_index()\n",
        "by_sport['Profit_Loss'] = pd.to_numeric(by_sport['Profit_Loss'], errors='coerce').round(2)\n",
        "\n",
        "by_country = df.groupby('Country')['Profit_Loss'].sum().reset_index()\n",
        "by_country['Profit_Loss'] = pd.to_numeric(by_country['Profit_Loss'], errors='coerce').round(2)\n",
        "\n",
        "sport_daily = {}\n",
        "for sport in df['Sport'].dropna().unique():\n",
        "    temp = df[df['Sport'] == sport].groupby('Day')['Profit_Loss'].sum().reset_index()\n",
        "    temp = temp.sort_values('Day').reset_index(drop=True)\n",
        "    temp['Cumulative_Profit_Loss'] = temp['Profit_Loss'].cumsum()\n",
        "    temp['Profit_Loss'] = pd.to_numeric(temp['Profit_Loss'], errors='coerce').round(2)\n",
        "    temp['Cumulative_Profit_Loss'] = pd.to_numeric(temp['Cumulative_Profit_Loss'], errors='coerce').round(2)\n",
        "    sport_daily[f\"{sport} Daily\"] = temp\n",
        "\n",
        "# Terminal output for validation\n",
        "print(f\"âœ… By Day rows: {len(by_day)}, dtype: {by_day['Profit_Loss'].dtype}\")\n",
        "print(f\"âœ… By Week rows: {len(by_week)}, dtype: {by_week['Profit_Loss'].dtype}\")\n",
        "print(f\"âœ… By Month rows: {len(by_month)}, dtype: {by_month['Profit_Loss'].dtype}\")\n",
        "print(f\"âœ… By Sport rows: {len(by_sport)}, dtype: {by_sport['Profit_Loss'].dtype}\")\n",
        "print(f\"âœ… By Country rows: {len(by_country)}, dtype: {by_country['Profit_Loss'].dtype}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V_K4tw9-cWvw",
        "outputId": "1f607810-c2cd-40a3-bd9f-0457ad312e73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… By Day rows: 187, dtype: float64\n",
            "âœ… By Week rows: 27, dtype: float64\n",
            "âœ… By Month rows: 7, dtype: float64\n",
            "âœ… By Sport rows: 14, dtype: float64\n",
            "âœ… By Country rows: 8, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- STEP 6: Track summaries ---\n",
        "track_df = df[df['Sport'].isin(['Horse Racing', 'Greyhound Racing'])] \\\n",
        "    .groupby(['Sport', 'Track_Name'])['Profit_Loss'].sum().reset_index()\n",
        "\n",
        "track_df['Profit_Loss'] = track_df['Profit_Loss'].round(2)\n",
        "\n",
        "tracks = {\n",
        "    'Top Horse Tracks': track_df.query(\"Sport == 'Horse Racing'\").nlargest(15, 'Profit_Loss'),\n",
        "    'Bottom Horse Tracks': track_df.query(\"Sport == 'Horse Racing'\").nsmallest(15, 'Profit_Loss'),\n",
        "    'Top Greyhound Tracks': track_df.query(\"Sport == 'Greyhound Racing'\").nlargest(15, 'Profit_Loss'),\n",
        "    'Bottom Greyhound Tracks': track_df.query(\"Sport == 'Greyhound Racing'\").nsmallest(15, 'Profit_Loss')\n",
        "}\n",
        "\n",
        "track_stats = track_df\n",
        "print(\"âœ… Track summaries built.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nFAP0CNsccL9",
        "outputId": "2f167807-8e28-48ad-ac8e-663b4980c383"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Track summaries built.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- STEP 7: Compute strike rates for Horse Racing and Greyhound Racing with min 50 bets ---\n",
        "\n",
        "# Filter for racing sports\n",
        "df_racing = df[df['Sport'].isin(['Horse Racing', 'Greyhound Racing'])].copy()\n",
        "\n",
        "# Group and compute\n",
        "strike_df = (\n",
        "    df_racing.groupby(['Sport', 'Track_Name'])['Profit_Loss']\n",
        "    .agg(\n",
        "        total_bets='count',\n",
        "        wins=lambda x: (x > 0).sum()\n",
        "    )\n",
        "    .reset_index()\n",
        ")\n",
        "\n",
        "# Calculate strike rate\n",
        "strike_df['Strike_Rate'] = strike_df['wins'] / strike_df['total_bets']\n",
        "\n",
        "# Filter for min 50 bets\n",
        "strike_df_filtered = strike_df[strike_df['total_bets'] >= 50]\n",
        "\n",
        "# Top/bottom\n",
        "top_strike = strike_df_filtered.nlargest(10, 'Strike_Rate')\n",
        "bottom_strike = strike_df_filtered.nsmallest(10, 'Strike_Rate')\n",
        "\n",
        "# Preview\n",
        "print(\"âœ… Strike rates computed (min 50 bets).\")\n",
        "print(strike_df_filtered.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YrBPZlTccebQ",
        "outputId": "0959cbfe-d8de-4f5c-9306-7fe90b97fdbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Strike rates computed (min 50 bets).\n",
            "              Sport   Track_Name  total_bets  wins  Strike_Rate\n",
            "0  Greyhound Racing  Albion Park         302   177     0.586093\n",
            "1  Greyhound Racing   Angle Park         158    89     0.563291\n",
            "2  Greyhound Racing     Ballarat         212   112     0.528302\n",
            "3  Greyhound Racing      Bendigo         150    70     0.466667\n",
            "6  Greyhound Racing   Cannington         345   200     0.579710\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- STEP 8: Prepare all_sheets for export ---\n",
        "all_sheets = {\n",
        "    'By Day': by_day,\n",
        "    'By Month': by_month,\n",
        "    'By Sport': by_sport,\n",
        "    'By Country': by_country,\n",
        "    \"Track Stats\": track_stats,\n",
        "    \"Top Strike Rates\": top_strike,\n",
        "    \"Bottom Strike Rates\": bottom_strike,\n",
        "    **tracks,\n",
        "    **sport_daily\n",
        "}\n",
        "\n",
        "print(f\"âœ… Prepared {len(all_sheets)} tables for Google Sheets export.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OP-sN4D9cgqN",
        "outputId": "cb42e525-d746-4a54-95cd-b8d092ed4c7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Prepared 25 tables for Google Sheets export.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"ðŸ“Š Top Horse Tracks preview:\")\n",
        "print(tracks['Top Horse Tracks'].head())\n",
        "print(\"ðŸ“Š Bottom Horse Tracks preview:\")\n",
        "print(tracks['Bottom Horse Tracks'].head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NfU0nlBeNY4n",
        "outputId": "43fec118-40b1-486f-d366-eef89f2be480"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“Š Top Horse Tracks preview:\n",
            "            Sport Track_Name Profit_Loss\n",
            "253  Horse Racing  Newcastle     1560.61\n",
            "313  Horse Racing  Southwell     1551.13\n",
            "167  Horse Racing  Geraldton     1400.78\n",
            "56   Horse Racing    Aintree     1270.77\n",
            "295  Horse Racing   Rosehill     1198.06\n",
            "ðŸ“Š Bottom Horse Tracks preview:\n",
            "            Sport    Track_Name Profit_Loss\n",
            "342  Horse Racing  Turfway Park     -336.93\n",
            "116  Horse Racing      Chepstow     -183.07\n",
            "213  Horse Racing     Lingfield     -168.89\n",
            "358  Horse Racing     Wincanton     -146.82\n",
            "343  Horse Racing     Uttoxeter     -105.35\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- STEP 9: Export to Google Sheets ---\n",
        "\n",
        "for name, df_out in all_sheets.items():\n",
        "    # Ensure Profit_Loss is numeric, then convert to string to prevent Sheets misinterpretation\n",
        "    if 'Profit_Loss' in df_out.columns:\n",
        "        df_out['Profit_Loss'] = pd.to_numeric(df_out['Profit_Loss'], errors='coerce').round(2)\n",
        "        df_out['Profit_Loss'] = df_out['Profit_Loss'].apply(lambda x: f\"{x:.2f}\" if pd.notnull(x) else \"\")\n",
        "        print(f\"âœ… {name} Profit_Loss dtype before upload: {df_out['Profit_Loss'].dtype}\")\n",
        "\n",
        "    # Convert Week Starting to string to avoid unwanted formatting\n",
        "    if 'Week Starting' in df_out.columns:\n",
        "        df_out['Week Starting'] = df_out['Week Starting'].astype(str)\n",
        "\n",
        "    # Round any remaining numeric columns\n",
        "    for col in df_out.select_dtypes(include=['float', 'int']).columns:\n",
        "        df_out[col] = df_out[col].round(2)\n",
        "\n",
        "    try:\n",
        "        ws = sh.worksheet(name)\n",
        "        ws.clear()\n",
        "    except gspread.exceptions.WorksheetNotFound:\n",
        "        ws = sh.add_worksheet(title=name, rows=1000, cols=20)\n",
        "\n",
        "    set_with_dataframe(ws, df_out)\n",
        "    print(f\"âœ… Uploaded {name}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sw42u_CuCOsx",
        "outputId": "d559bc82-e10e-4bc3-9877-5321c08cbbb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… By Day Profit_Loss dtype before upload: object\n",
            "âœ… Uploaded By Day\n",
            "âœ… By Day Sorted Profit_Loss dtype before upload: object\n",
            "âœ… Uploaded By Day Sorted\n",
            "âœ… By Week Profit_Loss dtype before upload: object\n",
            "âœ… Uploaded By Week\n",
            "âœ… By Month Profit_Loss dtype before upload: object\n",
            "âœ… Uploaded By Month\n",
            "âœ… By Sport Profit_Loss dtype before upload: object\n",
            "âœ… Uploaded By Sport\n",
            "âœ… By Country Profit_Loss dtype before upload: object\n",
            "âœ… Uploaded By Country\n",
            "âœ… Snooker Daily Profit_Loss dtype before upload: object\n",
            "âœ… Uploaded Snooker Daily\n",
            "âœ… Ice Hockey Daily Profit_Loss dtype before upload: object\n",
            "âœ… Uploaded Ice Hockey Daily\n",
            "âœ… Horse Racing Daily Profit_Loss dtype before upload: object\n",
            "âœ… Uploaded Horse Racing Daily\n",
            "âœ… Golf Daily Profit_Loss dtype before upload: object\n",
            "âœ… Uploaded Golf Daily\n",
            "âœ… Politics Daily Profit_Loss dtype before upload: object\n",
            "âœ… Uploaded Politics Daily\n",
            "âœ… Tennis Daily Profit_Loss dtype before upload: object\n",
            "âœ… Uploaded Tennis Daily\n",
            "âœ… Greyhound Racing Daily Profit_Loss dtype before upload: object\n",
            "âœ… Uploaded Greyhound Racing Daily\n",
            "âœ… Football Daily Profit_Loss dtype before upload: object\n",
            "âœ… Uploaded Football Daily\n",
            "âœ… Motor Sport Daily Profit_Loss dtype before upload: object\n",
            "âœ… Uploaded Motor Sport Daily\n",
            "âœ… Cricket Daily Profit_Loss dtype before upload: object\n",
            "âœ… Uploaded Cricket Daily\n",
            "âœ… Darts Daily Profit_Loss dtype before upload: object\n",
            "âœ… Uploaded Darts Daily\n",
            "âœ… Basketball Daily Profit_Loss dtype before upload: object\n",
            "âœ… Uploaded Basketball Daily\n",
            "âœ… American Football Daily Profit_Loss dtype before upload: object\n",
            "âœ… Uploaded American Football Daily\n",
            "âœ… Rugby Union Daily Profit_Loss dtype before upload: object\n",
            "âœ… Uploaded Rugby Union Daily\n",
            "âœ… Top Horse Tracks Profit_Loss dtype before upload: object\n",
            "âœ… Uploaded Top Horse Tracks\n",
            "âœ… Bottom Horse Tracks Profit_Loss dtype before upload: object\n",
            "âœ… Uploaded Bottom Horse Tracks\n",
            "âœ… Top Greyhound Tracks Profit_Loss dtype before upload: object\n",
            "âœ… Uploaded Top Greyhound Tracks\n",
            "âœ… Bottom Greyhound Tracks Profit_Loss dtype before upload: object\n",
            "âœ… Uploaded Bottom Greyhound Tracks\n",
            "âœ… Track Stats Profit_Loss dtype before upload: object\n",
            "âœ… Uploaded Track Stats\n",
            "âœ… Uploaded Top Strike Rates\n",
            "âœ… Uploaded Bottom Strike Rates\n"
          ]
        }
      ]
    }
  ]
}