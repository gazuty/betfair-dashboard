{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "1tbV1No038w0xJfNjEoodAMRm4uZdXZEj",
      "authorship_tag": "ABX9TyPF3lBQyytyrl7iwfBMfaDc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gazuty/betfair-dashboard/blob/main/Results.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- CONFIGURATION ---\n",
        "\n",
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "# ‚îÄ‚îÄ‚îÄ Your Drive / folder paths ‚îÄ‚îÄ‚îÄ\n",
        "BASE_FOLDER       = '/content/drive/My Drive/Betfair'\n",
        "MASTER_CSV        = os.path.join(BASE_FOLDER, 'Betfair_Master.csv')\n",
        "ARCHIVE_FOLDER    = os.path.join(BASE_FOLDER, 'Archive')\n",
        "BETTING_PATTERN   = os.path.join(BASE_FOLDER, 'BettingPandL*.csv')\n",
        "\n",
        "# ‚îÄ‚îÄ‚îÄ Google Sheet settings ‚îÄ‚îÄ‚îÄ\n",
        "GOOGLE_SHEET_NAME = 'Betfair Dashboard'\n",
        "\n",
        "# ‚îÄ‚îÄ‚îÄ Business rules ‚îÄ‚îÄ‚îÄ\n",
        "VALID_SPORTS      = ['Horse Racing', 'Greyhound Racing']\n",
        "MIN_STRIKE_BETS   = 50\n",
        "\n",
        "# ‚îÄ‚îÄ‚îÄ Setup ‚îÄ‚îÄ‚îÄ\n",
        "os.makedirs(ARCHIVE_FOLDER, exist_ok=True)\n",
        "\n",
        "print(\"‚úÖ Configuration loaded:\")\n",
        "print(f\"  BASE_FOLDER        = {BASE_FOLDER}\")\n",
        "print(f\"  MASTER_CSV         = {MASTER_CSV}\")\n",
        "print(f\"  ARCHIVE_FOLDER     = {ARCHIVE_FOLDER}\")\n",
        "print(f\"  BETTING_PATTERN    = {BETTING_PATTERN}\")\n",
        "print(f\"  GOOGLE_SHEET_NAME  = {GOOGLE_SHEET_NAME}\")\n",
        "print(f\"  VALID_SPORTS       = {VALID_SPORTS}\")\n",
        "print(f\"  MIN_STRIKE_BETS    = {MIN_STRIKE_BETS}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fy268ho4Fip2",
        "outputId": "641df582-7e09-4fd2-dd29-26c484b6d142"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Configuration loaded:\n",
            "  BASE_FOLDER        = /content/drive/My Drive/Betfair\n",
            "  MASTER_CSV         = /content/drive/My Drive/Betfair/Betfair_Master.csv\n",
            "  ARCHIVE_FOLDER     = /content/drive/My Drive/Betfair/Archive\n",
            "  BETTING_PATTERN    = /content/drive/My Drive/Betfair/BettingPandL*.csv\n",
            "  GOOGLE_SHEET_NAME  = Betfair Dashboard\n",
            "  VALID_SPORTS       = ['Horse Racing', 'Greyhound Racing']\n",
            "  MIN_STRIKE_BETS    = 50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- STEP 1: Master Updater ---\n",
        "\n",
        "import pandas as pd, glob, os, shutil\n",
        "\n",
        "REQUIRED_COLS = ['Market', 'Settled date']\n",
        "\n",
        "def update_betfair_master():\n",
        "    print(\"üîÑ Starting master update\")\n",
        "\n",
        "    # 1Ô∏è‚É£ Load or initialize master\n",
        "    if os.path.exists(MASTER_CSV):\n",
        "        df_master = pd.read_csv(MASTER_CSV)\n",
        "        df_master['Settled date'] = pd.to_datetime(df_master['Settled date'], errors='coerce')\n",
        "        df_master['Profit_Loss'] = pd.to_numeric(df_master['Profit_Loss'], errors='coerce')\n",
        "        df_master = df_master.dropna(subset=['Settled date']).reset_index(drop=True)\n",
        "        print(f\"‚úÖ Loaded master ({len(df_master)} rows)\")\n",
        "    else:\n",
        "        print(\"‚ö† No existing master found ‚Äî starting fresh\")\n",
        "        df_master = pd.DataFrame(columns=REQUIRED_COLS + ['Profit_Loss'])\n",
        "\n",
        "    # 2Ô∏è‚É£ Gather raw files\n",
        "    raw_files = glob.glob(BETTING_PATTERN)\n",
        "    print(f\"üìÇ Found {len(raw_files)} raw file(s)\")\n",
        "\n",
        "    if not raw_files:\n",
        "        print(\"‚ö† No raw files to process ‚Äî exiting.\")\n",
        "        return\n",
        "\n",
        "    # 3Ô∏è‚É£ Process each file\n",
        "    dfs = []\n",
        "    for filepath in raw_files:\n",
        "        fname = os.path.basename(filepath)\n",
        "        print(f\"üì• {fname}\", end=\"\")\n",
        "\n",
        "        df = pd.read_csv(filepath)\n",
        "        missing = [c for c in REQUIRED_COLS if c not in df.columns]\n",
        "        if missing:\n",
        "            print(f\" ‚Üí ‚ùå missing columns {missing}\")\n",
        "            continue\n",
        "\n",
        "        profs = [c for c in df.columns if 'profit' in c.lower()]\n",
        "        if not profs:\n",
        "            print(\" ‚Üí ‚ùå no profit column found\")\n",
        "            continue\n",
        "\n",
        "        pick = next((c for c in profs if 'aud' in c.lower()), profs[0])\n",
        "        df['Profit_Loss'] = pd.to_numeric(df[pick], errors='coerce')\n",
        "        df['Settled date'] = pd.to_datetime(df['Settled date'], errors='coerce')\n",
        "        df = df[['Market', 'Settled date', 'Profit_Loss']].dropna(subset=['Settled date'])\n",
        "\n",
        "        dfs.append(df)\n",
        "        print(f\" ‚Üí {len(df)} rows from '{pick}'\")\n",
        "\n",
        "    if not dfs:\n",
        "        print(\"‚ö† No valid data loaded from raw files ‚Äî exiting.\")\n",
        "        return\n",
        "\n",
        "    # 4Ô∏è‚É£ Combine and deduplicate\n",
        "    df_new = pd.concat(dfs, ignore_index=True)\n",
        "\n",
        "    # Drop invalid dates (again, to be safe)\n",
        "    df_new = df_new.dropna(subset=['Settled date']).reset_index(drop=True)\n",
        "\n",
        "    # Prepare deduplication keys\n",
        "    df_master['_key'] = (\n",
        "        df_master['Market'].astype(str) + \"|\" +\n",
        "        df_master['Settled date'].dt.strftime('%Y-%m-%d %H:%M:%S') + \"|\" +\n",
        "        df_master['Profit_Loss'].astype(str)\n",
        "    )\n",
        "    df_new['_key'] = (\n",
        "        df_new['Market'].astype(str) + \"|\" +\n",
        "        df_new['Settled date'].dt.strftime('%Y-%m-%d %H:%M:%S') + \"|\" +\n",
        "        df_new['Profit_Loss'].astype(str)\n",
        "    )\n",
        "\n",
        "    df_unique = df_new[~df_new['_key'].isin(df_master['_key'])]\n",
        "    print(f\"‚úÖ {len(df_unique)} unique new row(s) identified\")\n",
        "\n",
        "    # 5Ô∏è‚É£ Merge and save\n",
        "    if not df_unique.empty:\n",
        "        df_combined = pd.concat([\n",
        "            df_master.drop(columns=['_key']),\n",
        "            df_unique.drop(columns=['_key'])\n",
        "        ], ignore_index=True)\n",
        "        df_combined.to_csv(MASTER_CSV, index=False)\n",
        "        print(f\"‚úÖ Master updated ({len(df_combined)} rows) ‚Üí {MASTER_CSV}\")\n",
        "    else:\n",
        "        print(\"‚ö† No new rows to add ‚Äî master unchanged.\")\n",
        "\n",
        "    # 6Ô∏è‚É£ Archive files\n",
        "    for filepath in raw_files:\n",
        "        fname = os.path.basename(filepath)\n",
        "        shutil.move(filepath, os.path.join(ARCHIVE_FOLDER, fname))\n",
        "        print(f\"üì¶ Archived {fname}\")\n",
        "\n",
        "# Run the function\n",
        "update_betfair_master()\n"
      ],
      "metadata": {
        "id": "6Bgp_pFfIjKv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3eb46d6-b108-4ee4-919c-e154fcc62635"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîÑ Starting master update\n",
            "‚úÖ Loaded master (20752 rows)\n",
            "üìÇ Found 0 raw file(s)\n",
            "‚ö† No raw files to process ‚Äî exiting.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- STEP 2: Load Master ---\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "print(f\"üìÇ Loading master from: {MASTER_CSV}\")\n",
        "df = pd.read_csv(MASTER_CSV)\n",
        "\n",
        "# Ensure correct dtypes\n",
        "df['Settled date'] = pd.to_datetime(df['Settled date'], errors='coerce')\n",
        "df['Profit_Loss'] = pd.to_numeric(df['Profit_Loss'], errors='coerce')\n",
        "\n",
        "# Drop rows with invalid dates\n",
        "before = len(df)\n",
        "df = df.dropna(subset=['Settled date']).reset_index(drop=True)\n",
        "after = len(df)\n",
        "\n",
        "print(f\"‚úÖ {after} rows loaded (dropped {before - after} invalid dates).\")\n",
        "print(f\"   Profit_Loss dtype: {df['Profit_Loss'].dtype}\")\n"
      ],
      "metadata": {
        "id": "Ag8x2FTv98Bd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39580376-f6d1-4f19-811a-fa85f6eca431"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÇ Loading master from: /content/drive/My Drive/Betfair/Betfair_Master.csv\n",
            "‚úÖ 20752 rows loaded (dropped 0 invalid dates).\n",
            "   Profit_Loss dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- STEP 3: Feature Extraction ---\n",
        "\n",
        "# 1Ô∏è‚É£ Extract Sport from Market (first token before slash)\n",
        "df['Sport'] = df['Market'].str.extract(r'^([^/]+)/')[0].str.strip()\n",
        "\n",
        "# 2Ô∏è‚É£ Extract Track_Info and Event_Description for racing sports\n",
        "racing_mask = df['Sport'].isin(VALID_SPORTS)\n",
        "track_event = df.loc[racing_mask, 'Market'].str.extract(r'/\\s*(.*?)\\s*:\\s*(.*)')\n",
        "track_event.columns = ['Track_Info', 'Event_Description']\n",
        "df.loc[racing_mask, ['Track_Info', 'Event_Description']] = track_event\n",
        "\n",
        "# 3Ô∏è‚É£ Extract Country from parentheses in Track_Info\n",
        "df['Country'] = df['Track_Info'].str.extract(r'\\(([^)]+)\\)')[0]\n",
        "\n",
        "# 4Ô∏è‚É£ Fill missing country values\n",
        "df['Country'] = df['Country'].fillna('UK')  # Default to UK for missing codes\n",
        "df.loc[~df['Sport'].isin(VALID_SPORTS), 'Country'] = 'Unknown'  # Unknown for non-racing\n",
        "\n",
        "# 5Ô∏è‚É£ Clean up Track_Info to produce Track_Name (remove dates and country)\n",
        "df['Track_Name'] = (\n",
        "    df['Track_Info']\n",
        "      .str.replace(r'\\([^)]*\\)', '', regex=True)  # Remove (AUS), (US), etc.\n",
        "      .str.replace(r'\\b\\d{1,2}(?:st|nd|rd|th)?\\s+\\w+\\b', '', regex=True)  # Remove date-like tokens\n",
        "      .str.strip()\n",
        ")\n",
        "\n",
        "# 6Ô∏è‚É£ Preview output\n",
        "preview = df.loc[df['Track_Name'].notna(), ['Sport', 'Track_Name', 'Country']].drop_duplicates().head(10)\n",
        "print(\"‚úÖ Feature extraction complete ‚Äî first few tracks:\")\n",
        "print(preview)\n"
      ],
      "metadata": {
        "id": "3h7weeM--HWz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f5072b4-9c3e-40a1-e3e4-6f611462b695"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Feature extraction complete ‚Äî first few tracks:\n",
            "           Sport            Track_Name Country\n",
            "2   Horse Racing              Ballarat     AUS\n",
            "3   Horse Racing             Casterton     AUS\n",
            "5   Horse Racing          Charles Town      US\n",
            "6   Horse Racing       Canterbury Park      US\n",
            "7   Horse Racing      Evangeline Downs      US\n",
            "8   Horse Racing       Churchill Downs      US\n",
            "10  Horse Racing  Belmont At The Big A      US\n",
            "11  Horse Racing              Woodbine      US\n",
            "13  Horse Racing         Monmouth Park      US\n",
            "14  Horse Racing             Doncaster      UK\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- STEP 4: Build Summary Tables (Daily, Weekly, Monthly, Sport, Country, Rolling) ---\n",
        "\n",
        "# 4.0Ô∏è‚É£ Ensure all_sheets exists before assigning\n",
        "if 'all_sheets' not in locals():\n",
        "    all_sheets = {}\n",
        "\n",
        "# 4.1Ô∏è‚É£ Daily Summary (chronological daily summary with cumulative P/L)\n",
        "by_day = (\n",
        "    df.groupby(df['Settled date'].dt.date)['Profit_Loss']\n",
        "      .sum()\n",
        "      .reset_index(name='Profit_Loss')\n",
        "      .rename(columns={'Settled date': 'Day'})\n",
        ")\n",
        "by_day = by_day.sort_values('Day').reset_index(drop=True)\n",
        "by_day['Cumulative_Profit_Loss'] = by_day['Profit_Loss'].cumsum()\n",
        "by_day[['Profit_Loss', 'Cumulative_Profit_Loss']] = by_day[['Profit_Loss', 'Cumulative_Profit_Loss']].round(2)\n",
        "\n",
        "# 4.2Ô∏è‚É£ Rolling 2w, 4w, 8w (All Sports Combined) ‚Äî from 1 March onward\n",
        "by_day['Day'] = pd.to_datetime(by_day['Day'])\n",
        "rolling_start = pd.to_datetime('2025-03-01')\n",
        "rolling_df = by_day[by_day['Day'] >= rolling_start].copy()\n",
        "rolling_df = rolling_df.set_index('Day')\n",
        "\n",
        "# Calculate rolling sums\n",
        "rolling_df['Rolling_2w'] = by_day.set_index('Day')['Profit_Loss'].rolling(window='14D').sum()\n",
        "rolling_df['Rolling_4w'] = by_day.set_index('Day')['Profit_Loss'].rolling(window='28D').sum()\n",
        "rolling_df['Rolling_8w'] = by_day.set_index('Day')['Profit_Loss'].rolling(window='56D').sum()\n",
        "\n",
        "# Format for export\n",
        "rolling_df = rolling_df.drop(columns=['Profit_Loss', 'Cumulative_Profit_Loss']).reset_index().round(2)\n",
        "all_sheets['Rolling Returns'] = rolling_df\n",
        "\n",
        "# 4.2bÔ∏è‚É£ Rolling by Sport (Horse Racing & Greyhound Racing)\n",
        "ROLLING_SPORTS = ['Horse Racing', 'Greyhound Racing']\n",
        "rolling_by_sport = {}\n",
        "\n",
        "for sport in ROLLING_SPORTS:\n",
        "    df_sport = df[df['Sport'] == sport].copy()\n",
        "    daily = (\n",
        "        df_sport.groupby(df_sport['Settled date'].dt.date)['Profit_Loss']\n",
        "        .sum()\n",
        "        .reset_index(name='Profit_Loss')\n",
        "        .rename(columns={'Settled date': 'Day'})\n",
        "        .sort_values('Day')\n",
        "        .reset_index(drop=True)\n",
        "    )\n",
        "    daily['Day'] = pd.to_datetime(daily['Day'])\n",
        "    daily = daily[daily['Day'] >= rolling_start].copy().set_index('Day')\n",
        "\n",
        "    daily[f'{sport} 2w'] = daily['Profit_Loss'].rolling(window='14D').sum()\n",
        "    daily[f'{sport} 4w'] = daily['Profit_Loss'].rolling(window='28D').sum()\n",
        "    daily[f'{sport} 8w'] = daily['Profit_Loss'].rolling(window='56D').sum()\n",
        "\n",
        "    result = daily.drop(columns=['Profit_Loss']).reset_index().round(2)\n",
        "    rolling_by_sport[sport] = result\n",
        "\n",
        "# 4.3Ô∏è‚É£ Weekly Summary (week starts Sunday)\n",
        "by_week = (\n",
        "    df.set_index('Settled date')\n",
        "      .resample('W-SUN')['Profit_Loss']\n",
        "      .sum()\n",
        "      .reset_index()\n",
        "      .rename(columns={'Settled date': 'Week Starting'})\n",
        ")\n",
        "by_week['Profit_Loss'] = by_week['Profit_Loss'].round(2)\n",
        "\n",
        "# 4.4Ô∏è‚É£ Monthly Summary\n",
        "by_month = (\n",
        "    df.set_index('Settled date')\n",
        "      .resample('M')['Profit_Loss']\n",
        "      .sum()\n",
        "      .reset_index()\n",
        ")\n",
        "by_month['Month'] = by_month['Settled date'].dt.to_period('M').astype(str)\n",
        "by_month = by_month[['Month', 'Profit_Loss']]\n",
        "by_month['Profit_Loss'] = by_month['Profit_Loss'].round(2)\n",
        "\n",
        "# 4.5Ô∏è‚É£ Summary by Sport\n",
        "by_sport = (\n",
        "    df.groupby('Sport')['Profit_Loss']\n",
        "      .sum()\n",
        "      .reset_index()\n",
        "      .round({'Profit_Loss': 2})\n",
        ")\n",
        "\n",
        "# 4.6Ô∏è‚É£ Summary by Country\n",
        "by_country = (\n",
        "    df.groupby('Country')['Profit_Loss']\n",
        "      .sum()\n",
        "      .reset_index()\n",
        "      .round({'Profit_Loss': 2})\n",
        ")\n",
        "\n",
        "# 4.7Ô∏è‚É£ Daily Summaries for Each Sport (with cumulative P/L)\n",
        "sport_daily = {}\n",
        "for sport in df['Sport'].dropna().unique():\n",
        "    temp = (\n",
        "        df[df['Sport'] == sport]\n",
        "          .groupby(df['Settled date'].dt.date)['Profit_Loss']\n",
        "          .sum()\n",
        "          .reset_index(name='Profit_Loss')\n",
        "          .rename(columns={'Settled date': 'Day'})\n",
        "          .sort_values('Day')\n",
        "          .reset_index(drop=True)\n",
        "    )\n",
        "    temp['Cumulative_Profit_Loss'] = temp['Profit_Loss'].cumsum().round(2)\n",
        "    temp['Profit_Loss'] = temp['Profit_Loss'].round(2)\n",
        "    sport_daily[f\"{sport} Daily\"] = temp\n",
        "\n",
        "# 4.8Ô∏è‚É£ Summary Checks\n",
        "print(\"üìä Summary Table Checks:\")\n",
        "\n",
        "print(f\"‚Ä¢ By Day: {len(by_day)} rows ‚Äî last day: {by_day['Day'].max().date()}\")\n",
        "if not rolling_df.empty:\n",
        "    print(f\"‚Ä¢ Rolling Returns: {len(rolling_df)} rows ‚Äî last day: {rolling_df['Day'].max().date()}\")\n",
        "else:\n",
        "    print(\"‚Ä¢ Rolling Returns: ‚ùå Not created or empty\")\n",
        "for sport, df_r in rolling_by_sport.items():\n",
        "    print(f\"‚Ä¢ Rolling {sport}: {len(df_r)} rows ‚Äî last day: {df_r['Day'].max().date()}\")\n",
        "\n",
        "print(f\"‚Ä¢ By Week: {len(by_week)} rows ‚Äî last week starting: {by_week['Week Starting'].max().date()}\")\n",
        "print(f\"‚Ä¢ By Month: {len(by_month)} rows ‚Äî last month: {by_month['Month'].max()}\")\n",
        "print(f\"‚Ä¢ By Sport: {len(by_sport)} sports ‚Üí {by_sport['Sport'].tolist()}\")\n",
        "print(f\"‚Ä¢ By Country: {len(by_country)} countries ‚Üí {by_country['Country'].tolist()}\")\n",
        "print(f\"‚Ä¢ Sport Daily Summaries: {len(sport_daily)} sport sheets ‚Üí {list(sport_daily.keys())}\")\n"
      ],
      "metadata": {
        "id": "V_K4tw9-cWvw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7b332ea-6928-449d-dc38-b600dbf7e7dd"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-46-3818745833.py:70: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
            "  .resample('M')['Profit_Loss']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìä Summary Table Checks:\n",
            "‚Ä¢ By Day: 208 rows ‚Äî last day: 2025-07-27\n",
            "‚Ä¢ Rolling Returns: 149 rows ‚Äî last day: 2025-07-27\n",
            "‚Ä¢ Rolling Horse Racing: 149 rows ‚Äî last day: 2025-07-27\n",
            "‚Ä¢ Rolling Greyhound Racing: 149 rows ‚Äî last day: 2025-07-27\n",
            "‚Ä¢ By Week: 30 rows ‚Äî last week starting: 2025-07-27\n",
            "‚Ä¢ By Month: 7 rows ‚Äî last month: 2025-07\n",
            "‚Ä¢ By Sport: 16 sports ‚Üí ['American Football', 'Basketball', 'Cricket', 'Cycling', 'Darts', 'Football', 'Gaelic Games', 'Golf', 'Greyhound Racing', 'Horse Racing', 'Ice Hockey', 'Motor Sport', 'Politics', 'Rugby Union', 'Snooker', 'Tennis']\n",
            "‚Ä¢ By Country: 8 countries ‚Üí ['AUS', 'FRA', 'NZL', 'RSA', 'UAE', 'UK', 'US', 'Unknown']\n",
            "‚Ä¢ Sport Daily Summaries: 16 sport sheets ‚Üí ['Snooker Daily', 'Ice Hockey Daily', 'Horse Racing Daily', 'Golf Daily', 'Politics Daily', 'Tennis Daily', 'Greyhound Racing Daily', 'Football Daily', 'Motor Sport Daily', 'Cricket Daily', 'Darts Daily', 'Basketball Daily', 'American Football Daily', 'Rugby Union Daily', 'Cycling Daily', 'Gaelic Games Daily']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- STEP 5: Track Summaries ---\n",
        "\n",
        "# 1Ô∏è‚É£ Aggregate P/L per track for Horse and Greyhound Racing\n",
        "track_df = (\n",
        "    df[df['Sport'].isin(VALID_SPORTS)]\n",
        "      .groupby(['Sport', 'Track_Name'], as_index=False)['Profit_Loss']\n",
        "      .sum()\n",
        ")\n",
        "track_df['Profit_Loss'] = track_df['Profit_Loss'].round(2)\n",
        "\n",
        "# 2Ô∏è‚É£ Create summary groups\n",
        "tracks = {\n",
        "    'Track Stats':               track_df,\n",
        "    'Top Horse Tracks':          track_df.query(\"Sport == 'Horse Racing'\").nlargest(15, 'Profit_Loss'),\n",
        "    'Bottom Horse Tracks':       track_df.query(\"Sport == 'Horse Racing'\").nsmallest(15, 'Profit_Loss'),\n",
        "    'Top Greyhound Tracks':      track_df.query(\"Sport == 'Greyhound Racing'\").nlargest(15, 'Profit_Loss'),\n",
        "    'Bottom Greyhound Tracks':   track_df.query(\"Sport == 'Greyhound Racing'\").nsmallest(15, 'Profit_Loss'),\n",
        "}\n",
        "\n",
        "# 3Ô∏è‚É£ Preview sample\n",
        "print(\"‚úÖ Track summaries built.\")\n",
        "print(\" ‚Ä¢ Sample Track Stats:\")\n",
        "print(track_df.head())\n",
        "print(\" ‚Ä¢ Top Horse Tracks:\")\n",
        "print(tracks['Top Horse Tracks'][['Track_Name', 'Profit_Loss']].head())\n"
      ],
      "metadata": {
        "id": "nFAP0CNsccL9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca24ba53-317a-4f5b-d281-76802e978947"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Track summaries built.\n",
            " ‚Ä¢ Sample Track Stats:\n",
            "              Sport   Track_Name  Profit_Loss\n",
            "0  Greyhound Racing  Albion Park        91.77\n",
            "1  Greyhound Racing   Angle Park      -140.28\n",
            "2  Greyhound Racing     Ballarat        83.15\n",
            "3  Greyhound Racing      Bendigo       -33.49\n",
            "4  Greyhound Racing  Broken Hill        60.87\n",
            " ‚Ä¢ Top Horse Tracks:\n",
            "    Track_Name  Profit_Loss\n",
            "173  Geraldton      1400.78\n",
            "305   Rosehill      1334.32\n",
            "57     Aintree      1286.07\n",
            "324  Southwell      1053.37\n",
            "262  Newcastle      1024.64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- STEP 6: Strike Rates ---\n",
        "\n",
        "# 1Ô∏è‚É£ Filter to Horse & Greyhound Racing\n",
        "df_racing = df[df['Sport'].isin(VALID_SPORTS)].copy()\n",
        "\n",
        "# 2Ô∏è‚É£ Compute total bets and wins per track\n",
        "strike_df = (\n",
        "    df_racing\n",
        "      .groupby(['Sport', 'Track_Name'])['Profit_Loss']\n",
        "      .agg(\n",
        "          total_bets='count',\n",
        "          wins=lambda x: (x > 0).sum()\n",
        "      )\n",
        "      .reset_index()\n",
        ")\n",
        "\n",
        "# 3Ô∏è‚É£ Calculate strike rate\n",
        "strike_df['Strike_Rate'] = (strike_df['wins'] / strike_df['total_bets']).round(4)\n",
        "\n",
        "# 4Ô∏è‚É£ Filter by minimum bets threshold\n",
        "strike_df_filtered = strike_df[strike_df['total_bets'] >= MIN_STRIKE_BETS].reset_index(drop=True)\n",
        "\n",
        "# 5Ô∏è‚É£ Extract Top & Bottom Strike Rate Tracks\n",
        "top_strike    = strike_df_filtered.nlargest(10, 'Strike_Rate').reset_index(drop=True)\n",
        "bottom_strike = strike_df_filtered.nsmallest(10, 'Strike_Rate').reset_index(drop=True)\n",
        "\n",
        "# 6Ô∏è‚É£ Preview\n",
        "print(f\"‚úÖ Strike rates computed (min {MIN_STRIKE_BETS} bets):\")\n",
        "print(\"Top 10 Strike Rates:\")\n",
        "print(top_strike[['Sport', 'Track_Name', 'total_bets', 'wins', 'Strike_Rate']])\n",
        "print(\"\\nBottom 10 Strike Rates:\")\n",
        "print(bottom_strike[['Sport', 'Track_Name', 'total_bets', 'wins', 'Strike_Rate']])\n"
      ],
      "metadata": {
        "id": "YrBPZlTccebQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6bdb33c-66a5-42b3-cf44-d35c82dee7a2"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Strike rates computed (min 50 bets):\n",
            "Top 10 Strike Rates:\n",
            "          Sport Track_Name  total_bets  wins  Strike_Rate\n",
            "0  Horse Racing   Rosehill          84    69       0.8214\n",
            "1  Horse Racing    Chester          65    51       0.7846\n",
            "2  Horse Racing       York          73    55       0.7534\n",
            "3  Horse Racing  Ellerslie          55    40       0.7273\n",
            "4  Horse Racing   Brighton          62    45       0.7258\n",
            "5  Horse Racing   Saratoga          79    57       0.7215\n",
            "6  Horse Racing       Bath          50    36       0.7200\n",
            "7  Horse Racing  Chantilly          74    53       0.7162\n",
            "8  Horse Racing    Newbury          87    62       0.7126\n",
            "9  Horse Racing   Woodbine          54    38       0.7037\n",
            "\n",
            "Bottom 10 Strike Rates:\n",
            "              Sport    Track_Name  total_bets  wins  Strike_Rate\n",
            "0  Greyhound Racing        Hobart         151    68       0.4503\n",
            "1      Horse Racing  Charles Town          54    25       0.4630\n",
            "2  Greyhound Racing  Q2 Parklands          89    42       0.4719\n",
            "3  Greyhound Racing       Bendigo         170    81       0.4765\n",
            "4  Greyhound Racing    Shepparton         146    70       0.4795\n",
            "5  Greyhound Racing    Launceston         172    83       0.4826\n",
            "6      Horse Racing     Greyville          60    29       0.4833\n",
            "7      Horse Racing   Turffontein          91    45       0.4945\n",
            "8      Horse Racing    Kenilworth          90    45       0.5000\n",
            "9      Horse Racing  Market Rasen          52    26       0.5000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- STEP 7: Prepare all_sheets for export ---\n",
        "\n",
        "# 7.1Ô∏è‚É£ Ensure all_sheets exists\n",
        "if 'all_sheets' not in locals():\n",
        "    all_sheets = {}\n",
        "\n",
        "# 7.2Ô∏è‚É£ Add core summaries\n",
        "all_sheets.update({\n",
        "    'By Day':           by_day,\n",
        "    'By Day Sorted':    by_day.sort_values('Profit_Loss', ascending=False).reset_index(drop=True),\n",
        "    'By Week':          by_week,\n",
        "    'Cumulative':       by_day[['Day', 'Cumulative_Profit_Loss']].rename(columns={'Cumulative_Profit_Loss': 'Cumulative'}),\n",
        "    'By Month':         by_month,\n",
        "    'By Sport':         by_sport,\n",
        "    'By Country':       by_country,\n",
        "})\n",
        "\n",
        "# 7.3Ô∏è‚É£ Add track-level summaries\n",
        "all_sheets.update({\n",
        "    'Track Stats':             tracks['Track Stats'],\n",
        "    'Top Horse Tracks':        tracks['Top Horse Tracks'],\n",
        "    'Bottom Horse Tracks':     tracks['Bottom Horse Tracks'],\n",
        "    'Top Greyhound Tracks':    tracks['Top Greyhound Tracks'],\n",
        "    'Bottom Greyhound Tracks': tracks['Bottom Greyhound Tracks'],\n",
        "})\n",
        "\n",
        "# 7.4Ô∏è‚É£ Add strike rate summaries\n",
        "all_sheets.update({\n",
        "    'Top Strike Rates':    top_strike,\n",
        "    'Bottom Strike Rates': bottom_strike,\n",
        "})\n",
        "\n",
        "# 7.5Ô∏è‚É£ Add daily summaries for each sport\n",
        "all_sheets.update(sport_daily)\n",
        "\n",
        "# 7.6Ô∏è‚É£ Add rolling returns by sport\n",
        "for sport, df_rolling in rolling_by_sport.items():\n",
        "    sheet_name = f\"Rolling {sport}\"\n",
        "    all_sheets[sheet_name] = df_rolling\n",
        "\n",
        "# 7.7Ô∏è‚É£ Final review of included sheets\n",
        "print(f\"‚úÖ Prepared {len(all_sheets)} tables for export:\")\n",
        "for name in all_sheets:\n",
        "    print(f\"  ‚Ä¢ {name}\")\n"
      ],
      "metadata": {
        "id": "OP-sN4D9cgqN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b869074b-ef1f-44bd-80c8-98b6017e72bb"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Prepared 33 tables for export:\n",
            "  ‚Ä¢ By Day\n",
            "  ‚Ä¢ By Day Sorted\n",
            "  ‚Ä¢ By Week\n",
            "  ‚Ä¢ Cumulative\n",
            "  ‚Ä¢ By Month\n",
            "  ‚Ä¢ By Sport\n",
            "  ‚Ä¢ By Country\n",
            "  ‚Ä¢ Track Stats\n",
            "  ‚Ä¢ Top Horse Tracks\n",
            "  ‚Ä¢ Bottom Horse Tracks\n",
            "  ‚Ä¢ Top Greyhound Tracks\n",
            "  ‚Ä¢ Bottom Greyhound Tracks\n",
            "  ‚Ä¢ Top Strike Rates\n",
            "  ‚Ä¢ Bottom Strike Rates\n",
            "  ‚Ä¢ Snooker Daily\n",
            "  ‚Ä¢ Ice Hockey Daily\n",
            "  ‚Ä¢ Horse Racing Daily\n",
            "  ‚Ä¢ Golf Daily\n",
            "  ‚Ä¢ Politics Daily\n",
            "  ‚Ä¢ Tennis Daily\n",
            "  ‚Ä¢ Greyhound Racing Daily\n",
            "  ‚Ä¢ Football Daily\n",
            "  ‚Ä¢ Motor Sport Daily\n",
            "  ‚Ä¢ Cricket Daily\n",
            "  ‚Ä¢ Darts Daily\n",
            "  ‚Ä¢ Basketball Daily\n",
            "  ‚Ä¢ American Football Daily\n",
            "  ‚Ä¢ Rugby Union Daily\n",
            "  ‚Ä¢ Cycling Daily\n",
            "  ‚Ä¢ Gaelic Games Daily\n",
            "  ‚Ä¢ Rolling Horse Racing\n",
            "  ‚Ä¢ Rolling Greyhound Racing\n",
            "  ‚Ä¢ Rolling Returns\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"üìä Top Horse Tracks preview:\")\n",
        "print(tracks['Top Horse Tracks'].head())\n",
        "print(\"üìä Bottom Horse Tracks preview:\")\n",
        "print(tracks['Bottom Horse Tracks'].head())\n"
      ],
      "metadata": {
        "id": "NfU0nlBeNY4n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a490392-7561-485d-d7b8-92ed31b2f199"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìä Top Horse Tracks preview:\n",
            "            Sport Track_Name  Profit_Loss\n",
            "173  Horse Racing  Geraldton      1400.78\n",
            "305  Horse Racing   Rosehill      1334.32\n",
            "57   Horse Racing    Aintree      1286.07\n",
            "324  Horse Racing  Southwell      1053.37\n",
            "262  Horse Racing  Newcastle      1024.64\n",
            "üìä Bottom Horse Tracks preview:\n",
            "            Sport    Track_Name  Profit_Loss\n",
            "353  Horse Racing  Turfway Park      -336.93\n",
            "300  Horse Racing         Ripon      -156.60\n",
            "371  Horse Racing     Wincanton      -129.13\n",
            "369  Horse Racing      Wetherby      -103.88\n",
            "116  Horse Racing  Charles Town       -93.83\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- STEP 8: Export to Google Sheets ---\n",
        "\n",
        "import gspread\n",
        "from gspread_dataframe import set_with_dataframe\n",
        "from google.colab import auth\n",
        "from google.auth import default\n",
        "from datetime import date\n",
        "\n",
        "# 1Ô∏è‚É£ Authenticate and connect\n",
        "auth.authenticate_user()\n",
        "creds, _ = default()\n",
        "gc = gspread.authorize(creds)\n",
        "\n",
        "# 2Ô∏è‚É£ Open Google Sheet\n",
        "sh = next((s for s in gc.openall() if s.title == GOOGLE_SHEET_NAME), None)\n",
        "if not sh:\n",
        "    raise Exception(f\"‚ùå Sheet not found: {GOOGLE_SHEET_NAME}\")\n",
        "print(f\"‚úÖ Connected to '{GOOGLE_SHEET_NAME}'\")\n",
        "\n",
        "# 3Ô∏è‚É£ Upload each table\n",
        "for name, df_out in all_sheets.items():\n",
        "    # Format Profit_Loss\n",
        "    if 'Profit_Loss' in df_out.columns:\n",
        "        df_out['Profit_Loss'] = pd.to_numeric(df_out['Profit_Loss'], errors='coerce').round(2)\n",
        "        df_out['Profit_Loss'] = df_out['Profit_Loss'].map(lambda x: f\"{x:.2f}\" if pd.notnull(x) else \"\")\n",
        "\n",
        "    # Format week date\n",
        "    if 'Week Starting' in df_out.columns:\n",
        "        df_out['Week Starting'] = df_out['Week Starting'].astype(str)\n",
        "\n",
        "    # Round other numeric columns\n",
        "    for col in df_out.select_dtypes(include=['float', 'int']).columns:\n",
        "        df_out[col] = df_out[col].round(2)\n",
        "\n",
        "    # Upload to sheet\n",
        "    try:\n",
        "        ws = sh.worksheet(name)\n",
        "        ws.clear()\n",
        "    except gspread.exceptions.WorksheetNotFound:\n",
        "        ws = sh.add_worksheet(title=name, rows=1000, cols=20)\n",
        "\n",
        "    set_with_dataframe(ws, df_out)\n",
        "    print(f\"‚úÖ Uploaded tab: {name}\")\n",
        "\n",
        "# 4Ô∏è‚É£ Update KPI dashboard\n",
        "try:\n",
        "    dash = sh.worksheet('Dashboard')\n",
        "    dash.clear()\n",
        "except gspread.exceptions.WorksheetNotFound:\n",
        "    dash = sh.add_worksheet('Dashboard', rows=10, cols=5)\n",
        "\n",
        "total_profit = round(df['Profit_Loss'].sum(), 2)\n",
        "total_bets   = len(df)\n",
        "best_day     = df.groupby(df['Settled date'].dt.date)['Profit_Loss'].sum().idxmax()\n",
        "worst_day    = df.groupby(df['Settled date'].dt.date)['Profit_Loss'].sum().idxmin()\n",
        "\n",
        "kpis = [\n",
        "    ['Metric', 'Value'],\n",
        "    ['Total Profit/Loss', total_profit],\n",
        "    ['Number of Bets', total_bets],\n",
        "    ['Best Day', str(best_day)],\n",
        "    ['Worst Day', str(worst_day)],\n",
        "    ['Generated on', str(date.today())]\n",
        "]\n",
        "dash.update(values=kpis, range_name='A1')\n",
        "\n",
        "print(\"‚úÖ Dashboard KPIs updated\")\n"
      ],
      "metadata": {
        "id": "sw42u_CuCOsx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a38f7bf-7258-45b6-c9d6-fe85fea41336"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Connected to 'Betfair Dashboard'\n",
            "‚úÖ Uploaded tab: By Day\n",
            "‚úÖ Uploaded tab: By Day Sorted\n",
            "‚úÖ Uploaded tab: By Week\n",
            "‚úÖ Uploaded tab: Cumulative\n",
            "‚úÖ Uploaded tab: By Month\n",
            "‚úÖ Uploaded tab: By Sport\n",
            "‚úÖ Uploaded tab: By Country\n",
            "‚úÖ Uploaded tab: Track Stats\n",
            "‚úÖ Uploaded tab: Top Horse Tracks\n",
            "‚úÖ Uploaded tab: Bottom Horse Tracks\n",
            "‚úÖ Uploaded tab: Top Greyhound Tracks\n",
            "‚úÖ Uploaded tab: Bottom Greyhound Tracks\n",
            "‚úÖ Uploaded tab: Top Strike Rates\n",
            "‚úÖ Uploaded tab: Bottom Strike Rates\n",
            "‚úÖ Uploaded tab: Snooker Daily\n",
            "‚úÖ Uploaded tab: Ice Hockey Daily\n",
            "‚úÖ Uploaded tab: Horse Racing Daily\n",
            "‚úÖ Uploaded tab: Golf Daily\n",
            "‚úÖ Uploaded tab: Politics Daily\n",
            "‚úÖ Uploaded tab: Tennis Daily\n",
            "‚úÖ Uploaded tab: Greyhound Racing Daily\n",
            "‚úÖ Uploaded tab: Football Daily\n",
            "‚úÖ Uploaded tab: Motor Sport Daily\n",
            "‚úÖ Uploaded tab: Cricket Daily\n",
            "‚úÖ Uploaded tab: Darts Daily\n",
            "‚úÖ Uploaded tab: Basketball Daily\n",
            "‚úÖ Uploaded tab: American Football Daily\n",
            "‚úÖ Uploaded tab: Rugby Union Daily\n",
            "‚úÖ Uploaded tab: Cycling Daily\n",
            "‚úÖ Uploaded tab: Gaelic Games Daily\n",
            "‚úÖ Uploaded tab: Rolling Horse Racing\n",
            "‚úÖ Uploaded tab: Rolling Greyhound Racing\n",
            "‚úÖ Uploaded tab: Rolling Returns\n",
            "‚úÖ Dashboard KPIs updated\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_sII6iunFgwZ"
      },
      "execution_count": 51,
      "outputs": []
    }
  ]
}