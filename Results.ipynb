{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "1tbV1No038w0xJfNjEoodAMRm4uZdXZEj",
      "authorship_tag": "ABX9TyOVikLqSNEcAaA44OHqm+91",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gazuty/betfair-dashboard/blob/main/Results.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- CONFIGURATION ---\n",
        "\n",
        "import os, glob\n",
        "\n",
        "# ‚îÄ‚îÄ‚îÄ Your Drive / folder paths ‚îÄ‚îÄ‚îÄ\n",
        "BASE_FOLDER      = '/content/drive/My Drive/Betfair'\n",
        "MASTER_CSV       = os.path.join(BASE_FOLDER, 'Betfair_Master.csv')\n",
        "ARCHIVE_FOLDER   = os.path.join(BASE_FOLDER, 'Archive')\n",
        "BETTING_PATTERN  = os.path.join(BASE_FOLDER, 'BettingPandL*.csv')\n",
        "RESULTS_FILE     = os.path.join(BASE_FOLDER, 'Results Summary export 25-05-11 095900.csv')\n",
        "\n",
        "# ‚îÄ‚îÄ‚îÄ Google Sheet name ‚îÄ‚îÄ‚îÄ\n",
        "GOOGLE_SHEET_NAME = 'Betfair Dashboard'\n",
        "\n",
        "# ‚îÄ‚îÄ‚îÄ Business rules ‚îÄ‚îÄ‚îÄ\n",
        "VALID_SPORTS     = ['Horse Racing', 'Greyhound Racing']\n",
        "MIN_STRIKE_BETS  = 50\n",
        "\n",
        "# Ensure Archive folder exists\n",
        "os.makedirs(ARCHIVE_FOLDER, exist_ok=True)\n",
        "\n",
        "print(\"‚úÖ Configuration loaded:\")\n",
        "print(f\"  BASE_FOLDER      = {BASE_FOLDER}\")\n",
        "print(f\"  MASTER_CSV       = {MASTER_CSV}\")\n",
        "print(f\"  ARCHIVE_FOLDER   = {ARCHIVE_FOLDER}\")\n",
        "print(f\"  BETTING_PATTERN  = {BETTING_PATTERN}\")\n",
        "print(f\"  RESULTS_FILE     = {RESULTS_FILE}\")\n",
        "print(f\"  GOOGLE_SHEET_NAME= {GOOGLE_SHEET_NAME}\")\n",
        "print(f\"  VALID_SPORTS     = {VALID_SPORTS}\")\n",
        "print(f\"  MIN_STRIKE_BETS  = {MIN_STRIKE_BETS}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fy268ho4Fip2",
        "outputId": "79149259-6ba2-4616-bcf3-a400d92b8c8f"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Configuration loaded:\n",
            "  BASE_FOLDER      = /content/drive/My Drive/Betfair\n",
            "  MASTER_CSV       = /content/drive/My Drive/Betfair/Betfair_Master.csv\n",
            "  ARCHIVE_FOLDER   = /content/drive/My Drive/Betfair/Archive\n",
            "  BETTING_PATTERN  = /content/drive/My Drive/Betfair/BettingPandL*.csv\n",
            "  RESULTS_FILE     = /content/drive/My Drive/Betfair/Results Summary export 25-05-11 095900.csv\n",
            "  GOOGLE_SHEET_NAME= Betfair Dashboard\n",
            "  VALID_SPORTS     = ['Horse Racing', 'Greyhound Racing']\n",
            "  MIN_STRIKE_BETS  = 50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- STEP 1: Master Updater ---\n",
        "\n",
        "import os, glob, pandas as pd, shutil\n",
        "\n",
        "# Which raw-file columns must exist\n",
        "REQUIRED_COLS = ['Market', 'Settled date']\n",
        "\n",
        "def update_betfair_master():\n",
        "    print(\"üîÑ Starting master‚Äêupdate\")\n",
        "\n",
        "    # 1Ô∏è‚É£ Load or initialize master\n",
        "    if os.path.exists(MASTER_CSV):\n",
        "        df_master = pd.read_csv(MASTER_CSV)\n",
        "        df_master['Settled date'] = pd.to_datetime(df_master['Settled date'], errors='coerce')\n",
        "        df_master['Profit_Loss']   = pd.to_numeric(df_master['Profit_Loss'],   errors='coerce')\n",
        "        print(f\"‚úÖ Loaded master ({len(df_master)} rows)\")\n",
        "    else:\n",
        "        print(\"‚ö† No existing master found‚Äîstarting fresh\")\n",
        "        df_master = pd.DataFrame(columns=REQUIRED_COLS + ['Profit_Loss'])\n",
        "\n",
        "    # 2Ô∏è‚É£ Gather raw files\n",
        "    raw_files = glob.glob(BETTING_PATTERN)\n",
        "    if os.path.exists(RESULTS_FILE):\n",
        "        raw_files.append(RESULTS_FILE)\n",
        "    print(f\"üìÇ Found {len(raw_files)} raw file(s)\")\n",
        "\n",
        "    if not raw_files:\n",
        "        print(\"‚ö† No raw files to process‚Äîexiting.\")\n",
        "        return\n",
        "\n",
        "    # 3Ô∏è‚É£ Process each file\n",
        "    dfs = []\n",
        "    for filepath in raw_files:\n",
        "        fname = os.path.basename(filepath)\n",
        "        print(f\"üì• Reading {fname}\")\n",
        "        df = pd.read_csv(filepath)\n",
        "\n",
        "        # Validate required columns\n",
        "        missing = [c for c in REQUIRED_COLS if c not in df.columns]\n",
        "        if missing:\n",
        "            print(f\"‚ö† Skipping {fname}: missing columns {missing}\")\n",
        "            continue\n",
        "\n",
        "        # Detect profit column(s)\n",
        "        profs = [c for c in df.columns if 'profit' in c.lower()]\n",
        "        if not profs:\n",
        "            print(f\"‚ö† Skipping {fname}: no 'profit' column found\")\n",
        "            continue\n",
        "\n",
        "        # Prefer one containing 'aud'\n",
        "        pick = next((c for c in profs if 'aud' in c.lower()), profs[0])\n",
        "        df['Profit_Loss'] = pd.to_numeric(df[pick], errors='coerce')\n",
        "\n",
        "        # Keep only the three key columns\n",
        "        df = df[['Market', 'Settled date', 'Profit_Loss']]\n",
        "        dfs.append(df)\n",
        "        print(f\"  ‚Ü≥ used '{pick}' with {len(df)} rows\")\n",
        "\n",
        "    if not dfs:\n",
        "        print(\"‚ö† No valid data loaded from raw files‚Äîexiting.\")\n",
        "        return\n",
        "\n",
        "    # 4Ô∏è‚É£ Concatenate & clean\n",
        "    df_new = pd.concat(dfs, ignore_index=True)\n",
        "    df_new['Settled date'] = pd.to_datetime(df_new['Settled date'], errors='coerce')\n",
        "    before = len(df_new)\n",
        "    df_new = df_new.dropna(subset=['Settled date']).reset_index(drop=True)\n",
        "    print(f\"üîé {before} ‚Üí {len(df_new)} rows after dropping invalid dates\")\n",
        "\n",
        "    # 5Ô∏è‚É£ Deduplicate\n",
        "    # Build composite keys\n",
        "    df_master['_key'] = (\n",
        "        df_master['Market'].astype(str) + \"|\" +\n",
        "        df_master['Settled date'].dt.strftime('%Y-%m-%d %H:%M:%S') + \"|\" +\n",
        "        df_master['Profit_Loss'].astype(str)\n",
        "    )\n",
        "    df_new['_key'] = (\n",
        "        df_new['Market'].astype(str) + \"|\" +\n",
        "        df_new['Settled date'].dt.strftime('%Y-%m-%d %H:%M:%S') + \"|\" +\n",
        "        df_new['Profit_Loss'].astype(str)\n",
        "    )\n",
        "    df_unique = df_new[~df_new['_key'].isin(df_master['_key'])]\n",
        "    print(f\"‚úÖ {len(df_unique)} unique new row(s) identified\")\n",
        "\n",
        "    # 6Ô∏è‚É£ Merge & save\n",
        "    if not df_unique.empty:\n",
        "        df_combined = pd.concat([\n",
        "            df_master.drop(columns=['_key']),\n",
        "            df_unique.drop(columns=['_key'])\n",
        "        ], ignore_index=True)\n",
        "        df_combined.to_csv(MASTER_CSV, index=False)\n",
        "        print(f\"‚úÖ Master updated ({len(df_combined)} rows) ‚Üí {MASTER_CSV}\")\n",
        "    else:\n",
        "        print(\"‚ö† No new rows to add‚Äîmaster unchanged.\")\n",
        "\n",
        "    # 7Ô∏è‚É£ Archive processed files\n",
        "    for filepath in raw_files:\n",
        "        fname = os.path.basename(filepath)\n",
        "        shutil.move(filepath, os.path.join(ARCHIVE_FOLDER, fname))\n",
        "        print(f\"üì¶ Archived {fname}\")\n",
        "\n",
        "# Run it\n",
        "update_betfair_master()\n"
      ],
      "metadata": {
        "id": "6Bgp_pFfIjKv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6dca335-5f95-4a59-fe16-003fc5b6ed09"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîÑ Starting master‚Äêupdate\n",
            "‚úÖ Loaded master (18886 rows)\n",
            "üìÇ Found 0 raw file(s)\n",
            "‚ö† No raw files to process‚Äîexiting.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- STEP 2: Load Master ---\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "print(f\"Loading master from: {MASTER_CSV}\")\n",
        "df = pd.read_csv(MASTER_CSV)\n",
        "\n",
        "# Parse dates & numeric\n",
        "df['Settled date'] = pd.to_datetime(df['Settled date'], errors='coerce')\n",
        "df['Profit_Loss']   = pd.to_numeric(df['Profit_Loss'], errors='coerce')\n",
        "\n",
        "# Drop any rows without a valid Settled date\n",
        "before = len(df)\n",
        "df = df.dropna(subset=['Settled date']).reset_index(drop=True)\n",
        "after  = len(df)\n",
        "\n",
        "print(f\"‚úÖ {after} rows loaded (dropped {before-after} invalid dates). Profit_Loss dtype: {df['Profit_Loss'].dtype}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ag8x2FTv98Bd",
        "outputId": "f972b7f4-1f3d-4df3-f51a-d1b1ae126ca8"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading master from: /content/drive/My Drive/Betfair/Betfair_Master.csv\n",
            "‚úÖ 18886 rows loaded (dropped 0 invalid dates). Profit_Loss dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- STEP 3: Feature Extraction ---\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# 1Ô∏è‚É£ Extract Sport\n",
        "df['Sport'] = df['Market'].str.extract(r'^([^/]+)/')[0].str.strip()\n",
        "\n",
        "# 2Ô∏è‚É£ Extract raw Track_Info & Event_Description for racing sports\n",
        "mask = df['Sport'].isin(VALID_SPORTS)\n",
        "tmp = df.loc[mask, 'Market'].str.extract(r'/\\s*(.*?)\\s*:\\s*(.*)')\n",
        "tmp.columns = ['Track_Info','Event_Description']\n",
        "df.loc[mask, ['Track_Info','Event_Description']] = tmp\n",
        "\n",
        "# 3Ô∏è‚É£ Extract country code from Track_Info parentheses\n",
        "df['Country'] = df['Track_Info'].str.extract(r'\\(([^)]+)\\)')[0]\n",
        "\n",
        "# 4Ô∏è‚É£ Default missing country:\n",
        "#    ‚Äì Racing sports (no code) ‚Üí UK\n",
        "#    ‚Äì Others ‚Üí Unknown\n",
        "df['Country'] = df['Country'].fillna('UK')\n",
        "df.loc[~df['Sport'].isin(VALID_SPORTS), 'Country'] = 'Unknown'\n",
        "\n",
        "# 5Ô∏è‚É£ Clean up Track_Info into a nice Track_Name:\n",
        "df['Track_Name'] = (\n",
        "    df['Track_Info']\n",
        "      .str.replace(r'\\([^)]*\\)', '',   regex=True)   # strip parentheses\n",
        "      .str.replace(r'\\b\\d{1,2}(?:st|nd|rd|th)?\\s+\\w+\\b', '', regex=True)  # strip dates\n",
        "      .str.strip()\n",
        ")\n",
        "\n",
        "# 6Ô∏è‚É£ Quick preview\n",
        "preview = (\n",
        "    df.loc[df['Track_Name'].notna(), ['Sport','Track_Name','Country']]\n",
        "      .drop_duplicates()\n",
        "      .reset_index(drop=True)\n",
        "      .head(10)\n",
        ")\n",
        "print(\"‚úÖ Feature extraction complete ‚Äî first few tracks:\")\n",
        "print(preview)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3h7weeM--HWz",
        "outputId": "fcf22724-93f0-40a7-9bed-e1803f92bd95"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Feature extraction complete ‚Äî first few tracks:\n",
            "          Sport            Track_Name Country\n",
            "0  Horse Racing              Ballarat     AUS\n",
            "1  Horse Racing             Casterton     AUS\n",
            "2  Horse Racing          Charles Town      US\n",
            "3  Horse Racing       Canterbury Park      US\n",
            "4  Horse Racing      Evangeline Downs      US\n",
            "5  Horse Racing       Churchill Downs      US\n",
            "6  Horse Racing  Belmont At The Big A      US\n",
            "7  Horse Racing              Woodbine      US\n",
            "8  Horse Racing         Monmouth Park      US\n",
            "9  Horse Racing             Doncaster      UK\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- STEP 4: Build complete summary tables (daily, weekly, monthly, sport, country) ---\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# 1Ô∏è‚É£ By Day\n",
        "by_day = (\n",
        "    df.groupby(df['Settled date'].dt.date)['Profit_Loss']\n",
        "      .sum()\n",
        "      .reset_index(name='Profit_Loss')\n",
        "      .rename(columns={'Settled date':'Day'})\n",
        ")\n",
        "by_day = by_day.sort_values('Day').reset_index(drop=True)\n",
        "by_day['Cumulative_Profit_Loss'] = by_day['Profit_Loss'].cumsum()\n",
        "by_day['Profit_Loss']             = by_day['Profit_Loss'].round(2)\n",
        "by_day['Cumulative_Profit_Loss']  = by_day['Cumulative_Profit_Loss'].round(2)\n",
        "\n",
        "# 2Ô∏è‚É£ By Week (Monday-starting weeks)\n",
        "by_week = (\n",
        "    df.set_index('Settled date')\n",
        "      .resample('W-MON')['Profit_Loss']\n",
        "      .sum()\n",
        "      .reset_index()\n",
        "      .rename(columns={'Settled date':'Week Starting'})\n",
        ")\n",
        "by_week['Profit_Loss'] = by_week['Profit_Loss'].round(2)\n",
        "\n",
        "# 3Ô∏è‚É£ By Month\n",
        "by_month = (\n",
        "    df.set_index('Settled date')\n",
        "      .resample('M')['Profit_Loss']\n",
        "      .sum()\n",
        "      .reset_index()\n",
        ")\n",
        "by_month['Month']       = by_month['Settled date'].dt.to_period('M').astype(str)\n",
        "by_month = by_month[['Month','Profit_Loss']]\n",
        "by_month['Profit_Loss'] = by_month['Profit_Loss'].round(2)\n",
        "\n",
        "# 4Ô∏è‚É£ By Sport\n",
        "by_sport = df.groupby('Sport')['Profit_Loss'] \\\n",
        "             .sum() \\\n",
        "             .reset_index() \\\n",
        "             .round({'Profit_Loss':2})\n",
        "\n",
        "# 5Ô∏è‚É£ By Country\n",
        "by_country = df.groupby('Country')['Profit_Loss'] \\\n",
        "                .sum() \\\n",
        "                .reset_index() \\\n",
        "                .round({'Profit_Loss':2})\n",
        "\n",
        "# 6Ô∏è‚É£ Sport-specific daily + cumulative (replacing your sport_daily dict)\n",
        "sport_daily = {}\n",
        "for sport in df['Sport'].dropna().unique():\n",
        "    temp = (\n",
        "        df[df['Sport']==sport]\n",
        "          .groupby(df['Settled date'].dt.date)['Profit_Loss']\n",
        "          .sum()\n",
        "          .reset_index(name='Profit_Loss')\n",
        "    )\n",
        "    temp = temp.sort_values('Settled date').rename(columns={'Settled date':'Day'})\n",
        "    temp['Cumulative_Profit_Loss'] = temp['Profit_Loss'].cumsum().round(2)\n",
        "    temp['Profit_Loss']            = temp['Profit_Loss'].round(2)\n",
        "    sport_daily[f\"{sport} Daily\"]  = temp\n",
        "\n",
        "# 7Ô∏è‚É£ Terminal sanity checks\n",
        "print(f\"‚úÖ By Day rows: {len(by_day)}, last date: {by_day['Day'].max()}\")\n",
        "print(f\"‚úÖ By Week rows: {len(by_week)}, last week: {by_week['Week Starting'].max()}\")\n",
        "print(f\"‚úÖ By Month rows: {len(by_month)}, last month: {by_month['Month'].max()}\")\n",
        "print(f\"‚úÖ By Sport rows: {len(by_sport)} ({by_sport['Sport'].tolist()})\")\n",
        "print(f\"‚úÖ By Country rows: {len(by_country)} ({by_country['Country'].tolist()})\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V_K4tw9-cWvw",
        "outputId": "b919849b-da38-4c81-ac69-a1b4c80ca704"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-52-4183814525.py:30: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
            "  .resample('M')['Profit_Loss']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ By Day rows: 193, last date: 2025-07-12\n",
            "‚úÖ By Week rows: 28, last week: 2025-07-14 00:00:00\n",
            "‚úÖ By Month rows: 7, last month: 2025-07\n",
            "‚úÖ By Sport rows: 14 (['American Football', 'Basketball', 'Cricket', 'Darts', 'Football', 'Golf', 'Greyhound Racing', 'Horse Racing', 'Ice Hockey', 'Motor Sport', 'Politics', 'Rugby Union', 'Snooker', 'Tennis'])\n",
            "‚úÖ By Country rows: 8 (['AUS', 'FRA', 'NZL', 'RSA', 'UAE', 'UK', 'US', 'Unknown'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- STEP 5: Track Summaries ---\n",
        "\n",
        "# 1Ô∏è‚É£ Aggregate P/L per track (only horse + greyhound)\n",
        "track_df = (\n",
        "    df[df['Sport'].isin(VALID_SPORTS)]\n",
        "      .groupby(['Sport','Track_Name'], as_index=False)['Profit_Loss']\n",
        "      .sum()\n",
        ")\n",
        "\n",
        "# 2Ô∏è‚É£ Round Profit_Loss\n",
        "track_df['Profit_Loss'] = track_df['Profit_Loss'].round(2)\n",
        "\n",
        "# 3Ô∏è‚É£ Build summary dicts\n",
        "tracks = {\n",
        "    'Track Stats':        track_df,  # full table if you need it\n",
        "    'Top Horse Tracks':   track_df.query(\"Sport == 'Horse Racing'\").nlargest(15, 'Profit_Loss'),\n",
        "    'Bottom Horse Tracks':track_df.query(\"Sport == 'Horse Racing'\").nsmallest(15, 'Profit_Loss'),\n",
        "    'Top Greyhound Tracks':   track_df.query(\"Sport == 'Greyhound Racing'\").nlargest(15, 'Profit_Loss'),\n",
        "    'Bottom Greyhound Tracks':track_df.query(\"Sport == 'Greyhound Racing'\").nsmallest(15, 'Profit_Loss')\n",
        "}\n",
        "\n",
        "# 4Ô∏è‚É£ Quick preview\n",
        "print(\"‚úÖ Track summaries built.\")\n",
        "print(\" ‚Ä¢ Sample Track Stats:\")\n",
        "print(tracks['Track Stats'].head())\n",
        "print(\" ‚Ä¢ Top Horse Tracks:\")\n",
        "print(tracks['Top Horse Tracks'][['Track_Name','Profit_Loss']].head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nFAP0CNsccL9",
        "outputId": "c864df81-b149-4809-ea80-bddc5e239078"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Track summaries built.\n",
            " ‚Ä¢ Sample Track Stats:\n",
            "              Sport   Track_Name  Profit_Loss\n",
            "0  Greyhound Racing  Albion Park        91.77\n",
            "1  Greyhound Racing   Angle Park      -128.51\n",
            "2  Greyhound Racing     Ballarat        84.36\n",
            "3  Greyhound Racing      Bendigo        24.32\n",
            "4  Greyhound Racing  Broken Hill        52.63\n",
            " ‚Ä¢ Top Horse Tracks:\n",
            "    Track_Name  Profit_Loss\n",
            "169  Geraldton      1400.78\n",
            "57     Aintree      1286.07\n",
            "297   Rosehill      1198.06\n",
            "315  Southwell      1026.10\n",
            "255  Newcastle      1022.21\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- STEP 6: Strike Rates ---\n",
        "\n",
        "# 1Ô∏è‚É£ Only horse & greyhound\n",
        "df_racing = df[df['Sport'].isin(VALID_SPORTS)].copy()\n",
        "\n",
        "# 2Ô∏è‚É£ Compute total bets and wins per track\n",
        "strike_df = (\n",
        "    df_racing\n",
        "      .groupby(['Sport','Track_Name'])['Profit_Loss']\n",
        "      .agg(\n",
        "          total_bets='count',\n",
        "          wins=lambda x: (x > 0).sum()\n",
        "      )\n",
        "      .reset_index()\n",
        ")\n",
        "\n",
        "# 3Ô∏è‚É£ Calculate strike rate\n",
        "strike_df['Strike_Rate'] = (strike_df['wins'] / strike_df['total_bets']).round(4)\n",
        "\n",
        "# 4Ô∏è‚É£ Apply minimum-bets filter\n",
        "strike_df_filtered = strike_df[strike_df['total_bets'] >= MIN_STRIKE_BETS].reset_index(drop=True)\n",
        "\n",
        "# 5Ô∏è‚É£ Top & Bottom by strike rate\n",
        "top_strike    = strike_df_filtered.nlargest(10, 'Strike_Rate').reset_index(drop=True)\n",
        "bottom_strike = strike_df_filtered.nsmallest(10, 'Strike_Rate').reset_index(drop=True)\n",
        "\n",
        "# 6Ô∏è‚É£ Preview\n",
        "print(f\"‚úÖ Strike rates computed (min {MIN_STRIKE_BETS} bets):\")\n",
        "print(\"Top 10 Strike Rates:\")\n",
        "print(top_strike[['Sport','Track_Name','total_bets','wins','Strike_Rate']])\n",
        "print(\"\\nBottom 10 Strike Rates:\")\n",
        "print(bottom_strike[['Sport','Track_Name','total_bets','wins','Strike_Rate']])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YrBPZlTccebQ",
        "outputId": "37502598-301b-40e7-a743-184f4d604939"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Strike rates computed (min 50 bets):\n",
            "Top 10 Strike Rates:\n",
            "          Sport              Track_Name  total_bets  wins  Strike_Rate\n",
            "0  Horse Racing                Rosehill          76    61       0.8026\n",
            "1  Horse Racing                    York          56    43       0.7679\n",
            "2  Horse Racing                 Chester          51    39       0.7647\n",
            "3  Horse Racing                 Newbury          72    53       0.7361\n",
            "4  Horse Racing               Ellerslie          55    40       0.7273\n",
            "5  Horse Racing                Brighton          62    45       0.7258\n",
            "6  Horse Racing               Chantilly          72    52       0.7222\n",
            "7  Horse Racing             Musselburgh          59    42       0.7119\n",
            "8  Horse Racing  Horseshoe Indianapolis          94    66       0.7021\n",
            "9  Horse Racing                 Windsor          81    56       0.6914\n",
            "\n",
            "Bottom 10 Strike Rates:\n",
            "              Sport    Track_Name  total_bets  wins  Strike_Rate\n",
            "0  Greyhound Racing        Hobart         139    64       0.4604\n",
            "1  Greyhound Racing       Bendigo         156    73       0.4679\n",
            "2  Greyhound Racing    Shepparton         140    66       0.4714\n",
            "3  Greyhound Racing  Q2 Parklands          89    42       0.4719\n",
            "4      Horse Racing  Charles Town          50    24       0.4800\n",
            "5      Horse Racing    Kenilworth          83    40       0.4819\n",
            "6      Horse Racing     Greyville          56    27       0.4821\n",
            "7  Greyhound Racing    Launceston         165    80       0.4848\n",
            "8  Greyhound Racing   Q1 Lakeside         228   113       0.4956\n",
            "9      Horse Racing   Turffontein          77    39       0.5065\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- STEP 7: Prepare all_sheets for export ---\n",
        "\n",
        "# Core summaries\n",
        "all_sheets = {\n",
        "    'By Day':          by_day,\n",
        "    'By Day Sorted':   by_day,\n",
        "    'By Week':         by_week,\n",
        "    'Cumulative':      by_day[['Day','Cumulative_Profit_Loss']].rename(\n",
        "                           columns={'Cumulative_Profit_Loss':'Cumulative'}),\n",
        "    'By Month':        by_month,\n",
        "    'By Sport':        by_sport,\n",
        "    'By Country':      by_country,\n",
        "\n",
        "    # Track summaries\n",
        "    'Track Stats':         tracks['Track Stats'],\n",
        "    'Top Horse Tracks':    tracks['Top Horse Tracks'],\n",
        "    'Bottom Horse Tracks': tracks['Bottom Horse Tracks'],\n",
        "    'Top Greyhound Tracks':    tracks['Top Greyhound Tracks'],\n",
        "    'Bottom Greyhound Tracks': tracks['Bottom Greyhound Tracks'],\n",
        "\n",
        "    # Strike rates\n",
        "    'Top Strike Rates':    top_strike,\n",
        "    'Bottom Strike Rates': bottom_strike,\n",
        "}\n",
        "\n",
        "# Sport‚Äêspecific daily tabs\n",
        "all_sheets.update(sport_daily)\n",
        "\n",
        "print(f\"‚úÖ Prepared {len(all_sheets)} tables for export:\")\n",
        "for name in all_sheets:\n",
        "    print(f\"  ‚Ä¢ {name}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OP-sN4D9cgqN",
        "outputId": "839ee528-156e-4a56-bdbe-395ad4a0af45"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Prepared 28 tables for export:\n",
            "  ‚Ä¢ By Day\n",
            "  ‚Ä¢ By Day Sorted\n",
            "  ‚Ä¢ By Week\n",
            "  ‚Ä¢ Cumulative\n",
            "  ‚Ä¢ By Month\n",
            "  ‚Ä¢ By Sport\n",
            "  ‚Ä¢ By Country\n",
            "  ‚Ä¢ Track Stats\n",
            "  ‚Ä¢ Top Horse Tracks\n",
            "  ‚Ä¢ Bottom Horse Tracks\n",
            "  ‚Ä¢ Top Greyhound Tracks\n",
            "  ‚Ä¢ Bottom Greyhound Tracks\n",
            "  ‚Ä¢ Top Strike Rates\n",
            "  ‚Ä¢ Bottom Strike Rates\n",
            "  ‚Ä¢ Snooker Daily\n",
            "  ‚Ä¢ Ice Hockey Daily\n",
            "  ‚Ä¢ Horse Racing Daily\n",
            "  ‚Ä¢ Golf Daily\n",
            "  ‚Ä¢ Politics Daily\n",
            "  ‚Ä¢ Tennis Daily\n",
            "  ‚Ä¢ Greyhound Racing Daily\n",
            "  ‚Ä¢ Football Daily\n",
            "  ‚Ä¢ Motor Sport Daily\n",
            "  ‚Ä¢ Cricket Daily\n",
            "  ‚Ä¢ Darts Daily\n",
            "  ‚Ä¢ Basketball Daily\n",
            "  ‚Ä¢ American Football Daily\n",
            "  ‚Ä¢ Rugby Union Daily\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"üìä Top Horse Tracks preview:\")\n",
        "print(tracks['Top Horse Tracks'].head())\n",
        "print(\"üìä Bottom Horse Tracks preview:\")\n",
        "print(tracks['Bottom Horse Tracks'].head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NfU0nlBeNY4n",
        "outputId": "7a299ffc-6756-4694-d97c-1d01f7813484"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìä Top Horse Tracks preview:\n",
            "            Sport Track_Name  Profit_Loss\n",
            "169  Horse Racing  Geraldton      1400.78\n",
            "57   Horse Racing    Aintree      1286.07\n",
            "297  Horse Racing   Rosehill      1198.06\n",
            "315  Horse Racing  Southwell      1026.10\n",
            "255  Horse Racing  Newcastle      1022.21\n",
            "üìä Bottom Horse Tracks preview:\n",
            "            Sport    Track_Name  Profit_Loss\n",
            "344  Horse Racing  Turfway Park      -336.93\n",
            "292  Horse Racing         Ripon      -154.66\n",
            "360  Horse Racing     Wincanton      -129.13\n",
            "358  Horse Racing      Wetherby      -103.88\n",
            "171  Horse Racing    Gold Coast       -89.16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- STEP 8: Export to Google Sheets ---\n",
        "\n",
        "import pandas as pd\n",
        "import gspread\n",
        "from gspread_dataframe import set_with_dataframe\n",
        "from google.colab import auth\n",
        "from google.auth import default\n",
        "from datetime import date\n",
        "\n",
        "# 1Ô∏è‚É£ Authenticate\n",
        "auth.authenticate_user()\n",
        "creds, _ = default()\n",
        "gc = gspread.authorize(creds)\n",
        "\n",
        "# 2Ô∏è‚É£ Open your spreadsheet\n",
        "sh = next((s for s in gc.openall() if s.title == GOOGLE_SHEET_NAME), None)\n",
        "if not sh:\n",
        "    raise Exception(f\"‚ùå Unable to find sheet named '{GOOGLE_SHEET_NAME}'\")\n",
        "print(f\"‚úÖ Connected to '{GOOGLE_SHEET_NAME}'\")\n",
        "\n",
        "# 3Ô∏è‚É£ Upload each table\n",
        "for name, df_out in all_sheets.items():\n",
        "    # Format Profit_Loss as two‚Äêdecimal text\n",
        "    if 'Profit_Loss' in df_out.columns:\n",
        "        df_out['Profit_Loss'] = pd.to_numeric(df_out['Profit_Loss'], errors='coerce').round(2)\n",
        "        df_out['Profit_Loss'] = df_out['Profit_Loss'].map(lambda x: f\"{x:.2f}\" if pd.notnull(x) else \"\")\n",
        "    # Ensure week field is text\n",
        "    if 'Week Starting' in df_out.columns:\n",
        "        df_out['Week Starting'] = df_out['Week Starting'].astype(str)\n",
        "    # Round any other numerics\n",
        "    for col in df_out.select_dtypes(['float','int']):\n",
        "        df_out[col] = df_out[col].round(2)\n",
        "\n",
        "    # Clear or create tab\n",
        "    try:\n",
        "        ws = sh.worksheet(name)\n",
        "        ws.clear()\n",
        "    except gspread.exceptions.WorksheetNotFound:\n",
        "        ws = sh.add_worksheet(title=name, rows=1000, cols=20)\n",
        "\n",
        "    set_with_dataframe(ws, df_out)\n",
        "    print(f\"‚úÖ Uploaded tab: {name}\")\n",
        "\n",
        "# 4Ô∏è‚É£ (Optional) Update Dashboard KPIs\n",
        "try:\n",
        "    dash = sh.worksheet('Dashboard')\n",
        "    dash.clear()\n",
        "except gspread.exceptions.WorksheetNotFound:\n",
        "    dash = sh.add_worksheet('Dashboard', rows=10, cols=5)\n",
        "\n",
        "total_profit = round(df['Profit_Loss'].sum(), 2)\n",
        "total_bets   = len(df)\n",
        "best_day     = df.groupby(df['Settled date'].dt.date)['Profit_Loss'].sum().idxmax()\n",
        "worst_day    = df.groupby(df['Settled date'].dt.date)['Profit_Loss'].sum().idxmin()\n",
        "\n",
        "kpis = [\n",
        "    ['Metric','Value'],\n",
        "    ['Total Profit/Loss', total_profit],\n",
        "    ['Number of Bets', total_bets],\n",
        "    ['Best Day', str(best_day)],\n",
        "    ['Worst Day', str(worst_day)],\n",
        "    ['Generated on', str(date.today())]\n",
        "]\n",
        "dash.update('A1', kpis)\n",
        "print(\"‚úÖ Dashboard KPIs updated\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sw42u_CuCOsx",
        "outputId": "ded5cd59-16c2-4adc-cc2f-d4b39acd3a8b"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Connected to 'Betfair Dashboard'\n",
            "‚úÖ Uploaded tab: By Day\n",
            "‚úÖ Uploaded tab: By Day Sorted\n",
            "‚úÖ Uploaded tab: By Week\n",
            "‚úÖ Uploaded tab: Cumulative\n",
            "‚úÖ Uploaded tab: By Month\n",
            "‚úÖ Uploaded tab: By Sport\n",
            "‚úÖ Uploaded tab: By Country\n",
            "‚úÖ Uploaded tab: Track Stats\n",
            "‚úÖ Uploaded tab: Top Horse Tracks\n",
            "‚úÖ Uploaded tab: Bottom Horse Tracks\n",
            "‚úÖ Uploaded tab: Top Greyhound Tracks\n",
            "‚úÖ Uploaded tab: Bottom Greyhound Tracks\n",
            "‚úÖ Uploaded tab: Top Strike Rates\n",
            "‚úÖ Uploaded tab: Bottom Strike Rates\n",
            "‚úÖ Uploaded tab: Snooker Daily\n",
            "‚úÖ Uploaded tab: Ice Hockey Daily\n",
            "‚úÖ Uploaded tab: Horse Racing Daily\n",
            "‚úÖ Uploaded tab: Golf Daily\n",
            "‚úÖ Uploaded tab: Politics Daily\n",
            "‚úÖ Uploaded tab: Tennis Daily\n",
            "‚úÖ Uploaded tab: Greyhound Racing Daily\n",
            "‚úÖ Uploaded tab: Football Daily\n",
            "‚úÖ Uploaded tab: Motor Sport Daily\n",
            "‚úÖ Uploaded tab: Cricket Daily\n",
            "‚úÖ Uploaded tab: Darts Daily\n",
            "‚úÖ Uploaded tab: Basketball Daily\n",
            "‚úÖ Uploaded tab: American Football Daily\n",
            "‚úÖ Uploaded tab: Rugby Union Daily\n",
            "‚úÖ Dashboard KPIs updated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-57-1949051070.py:64: DeprecationWarning: The order of arguments in worksheet.update() has changed. Please pass values first and range_name secondor used named arguments (range_name=, values=)\n",
            "  dash.update('A1', kpis)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_sII6iunFgwZ"
      },
      "execution_count": 57,
      "outputs": []
    }
  ]
}